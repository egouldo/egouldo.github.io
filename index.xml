<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Elise Gould: PhD Research Notebook</title>
    <link>/</link>
    <description>Recent content on Elise Gould: PhD Research Notebook</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>elise.gould@unimelb.edu.au (Elise Gould)</managingEditor>
    <webMaster>elise.gould@unimelb.edu.au (Elise Gould)</webMaster>
    <copyright>(c) 2018 -- All rights reserved.</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +1100</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Academic</title>
      <link>/home/hero/</link>
      <pubDate>Sun, 15 Oct 2017 00:00:00 +1100</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/home/hero/</guid>
      <description>The highly flexible website framework for Hugo with an extensible plugin mechanism. Create a beautifully simple site in under 10 minutes üöÄ Latest release  
(function defer() { if (window.jQuery) { jQuery(document).ready(function(){ GetLatestReleaseInfo(); }); } else { setTimeout(function() { defer() }, 50); } })(); function GetLatestReleaseInfo() { $.getJSON(&#39;https://api.github.com/repos/gcushen/hugo-academic/tags&#39;).done(function (json) { let release = json[0]; // let downloadURL = release.zipball_url; $(&#39;#academic-release&#39;).text(&#39;Latest release &#39; + release.name); }); }  </description>
    </item>
    
    <item>
      <title></title>
      <link>/home/about/</link>
      <pubDate>Thu, 15 Feb 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/home/about/</guid>
      <description>Biography I am a PhD student at the Centre of Excellence for Biosecurity and Risk Analysis (CEBRA), University of Melbourne. This is my research notebook for all things PhD.</description>
    </item>
    
    <item>
      <title>Selected Publications</title>
      <link>/home/publications_selected/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +1000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/home/publications_selected/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Recent Publications</title>
      <link>/home/publications/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +1000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/home/publications/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Recent &amp; Upcoming Talks</title>
      <link>/home/talks/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/home/talks/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Recent Posts</title>
      <link>/home/posts/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +1000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/home/posts/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>/home/projects/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/home/projects/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Teaching</title>
      <link>/home/teaching/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/home/teaching/</guid>
      <description>This is an example of using the custom widget to create your own homepage section.
I am a teaching instructor for the following courses at University X:
 CS101: An intro to computer science CS102: An intro to computer science CS103: An intro to computer science CS104: An intro to computer science CS105: An intro to computer science CS106: An intro to computer science CS107: An intro to computer science  </description>
    </item>
    
    <item>
      <title>Tags</title>
      <link>/home/tags/</link>
      <pubDate>Wed, 20 Sep 2017 00:00:00 +1000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/home/tags/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>/home/contact/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/home/contact/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Meeting-20-Dec-2018</title>
      <link>/posts/meeting-20-dec-2018/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-20-dec-2018/</guid>
      <description>Present: HF, FF, LR, EG
Problems with the proposed QRP modelling method HF How necessary is it going to be to have covariates at the study/trial level? It will poptentially be cumbersome and problematic. Can we just have an uninformative error term to soak up between-study variation?
cumbersome to implement
 must pre-identify articles for each participant, asking them about specific papers (logistically problematic, how do we find appropriate studies? The author must also be the person who conducted the analyses, and it may not be easy to find contact details for them) ask participants to specify a fixed number of studies in which they used the analysis type (although not necessary for the model, restricting n is going to be better for the people answering the question, and more tractible for me)‚Ä¶ then we need to pipe these studies through to the rest of the survey some how.</description>
    </item>
    
    <item>
      <title>Replicating Models - Talks with Neil</title>
      <link>/posts/replicating-models-talks-with-neil/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/replicating-models-talks-with-neil/</guid>
      <description>Experiment Description ft. God, Mere mortals and steve the synthesiser. UPDATE WITH NOTES FROM NEIL MEETING
 Reasons why this is a good idea ‚ÄúGOD‚Äù ‚Äì We never have truth to compare to! This will be a unique opportunity to be able to properly evaluate models and their deviation from some truth. We can see where in the causal strucutre people keep getting things wrong ‚Äì are there commonalities? Is there overlap in parts of their model structure?</description>
    </item>
    
    <item>
      <title>Adaptive Pre-registration</title>
      <link>/posts/adaptive-pre-registration/</link>
      <pubDate>Thu, 20 Dec 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/adaptive-pre-registration/</guid>
      <description>Context, situate paper Discuss definition of RDF / QRPs Challenges and Barriers Strategies for Adaptive Pre-registration  Why I chose this paper  Neat explanation of researcher degrees of freedom (analagous to QRP‚Äôs), that makes sense in the context of non-hypothesis testing research. clear articulation of challenges to pre-registration in complicated research, and creative strategies. In the past when we‚Äôve had conversations about pre-registration, it hasn‚Äôt been very clear how we might move forward to implementing that in this field.</description>
    </item>
    
    <item>
      <title>Meeting-Dec-2018-Jian</title>
      <link>/posts/meeting-dec-2018/</link>
      <pubDate>Tue, 18 Dec 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-dec-2018/</guid>
      <description>Really good meeting with Jian, lots of ideas.
Things to look up:
 Near-term forecasting (as a reproducibility / RDF ) Multiverse problem ~ are there parallels to the simulation study Neil and I have been talking about?  Multiverse problem intra versus inter person variation.
Can you replicate a multiverse for an individual? Get people to come up with 10 models each and then compare.
So there‚Äôs model uncertainty and then subjective uncertainty (Ray and Burgman).</description>
    </item>
    
    <item>
      <title>Meeting December 13</title>
      <link>/posts/meeting-december-13/</link>
      <pubDate>Fri, 14 Dec 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-december-13/</guid>
      <description>Present: FF, HF, LR, EG
Recap, what we talked about 1. Scope and framing of the thesis Agreed that broad framing ‚Äúreproducibility of decisions‚Äù is good to retain. Need to be be careful about explicitly framing the scope of the thesis in this framing, however.
FF reminded me of another (crucial!) point as to why biasing conditions might be unique in a decision-making context: DM under time-constraints ‚Äì need to act (quickly)!</description>
    </item>
    
    <item>
      <title>Modelling QRP Engagement as an Occupancy-Detection Problem</title>
      <link>/posts/estimating-background-qrp-rate/</link>
      <pubDate>Fri, 14 Dec 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/estimating-background-qrp-rate/</guid>
      <description>Status: WORK IN PROGRESS ‚Äì DRAFT Problem 1: Estimating the percentage of researchers who engage in a particular QRP provides some information about the extent of the practice, and its potential impact on the literature. However, it doesn‚Äôt allow us to get an estimate of how many studies or papers might have been affected by this QRP ‚Äì this is what we really care about, and the proportion of researchers engaging in a practice will not translate very accurately (or precisely) to the proportion of the literature effected.</description>
    </item>
    
    <item>
      <title>ACEMS workshop: modelling, experiments, data - what constitutes scientific evidence?</title>
      <link>/posts/acems-workshop-modelling-experiments-data-what-constitutes-scientific-evidence/</link>
      <pubDate>Wed, 12 Dec 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/acems-workshop-modelling-experiments-data-what-constitutes-scientific-evidence/</guid>
      <description>James McCaw: How models change the value of observational data? Empirical vs.¬†theory driven research Physics is quintessential example of theory driven area. Psychology, if completely empirical and basic laws are unknown, psychology is trying to discover what the law is. Mathematical laws are used to analyse the data
Immunology - also a deeply theoretical or conceptually driven field. But the way that the science is done is completely empirical. Theory motivated, qualitative, conceptual model, analyse the data using ANOVA etc.</description>
    </item>
    
    <item>
      <title>confirmationnotes</title>
      <link>/posts/confirmation-notes/</link>
      <pubDate>Mon, 10 Dec 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/confirmation-notes/</guid>
      <description>Here are my notes of the issues raised during the confirmation meeting to be followed up, and some initial thoughts / responses to them.
1. Scope: reproducibility of decisions vs.¬†reproducibility for decisions. PV took issue with the framing / scope of the PhD ‚Äì namely that tackling reproducibility of decisions is too big of a task for the PhD. Need to first evaluate reproducibility for decisions first.
I agree with PV‚Äôs point that looking at reproducibility of decisions is too big of a task for this PhD.</description>
    </item>
    
    <item>
      <title>pre-print Sound Inference in Compliacted Research: A Multi-Strategy Approach</title>
      <link>/posts/pre-print-sound-inference-in-compliacted-research-a-multi-strategy-approach/</link>
      <pubDate>Sun, 25 Nov 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/pre-print-sound-inference-in-compliacted-research-a-multi-strategy-approach/</guid>
      <description>Whole article: addresses the problem of people categorically dismissing pre-registration, especially in ecology.
Pre-reg can address all sorts of biases, examples of complicated research and what this might mean were good.
Conceptual Framework: Also good, liked their use of Loken and Gelman. Have been leaning towards this thinking for my own rok.
What do you think about trying this in a case study paper? A demonstration of pre-reg for ‚Äòcomplicated research‚Äô would that be a useful contribution?</description>
    </item>
    
    <item>
      <title>test post</title>
      <link>/posts/test-post/</link>
      <pubDate>Thu, 22 Nov 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/test-post/</guid>
      <description></description>
    </item>
    
    <item>
      <title>QRPs in non-hypothesis testing research</title>
      <link>/posts/qrps-in-non-hypothesis-testing-research/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/qrps-in-non-hypothesis-testing-research/</guid>
      <description>QRP research is NHST focussed To date, there has been limited research on QRPs and other aspects of reproducibility for non-NHST research.
Partly because: The majority of QRP research has been undertaken in Psychology, where almost all statistical testing is NHST. But this is not true for other fields eg, in applied ecology and conservation, my area of expertise, where we often use predictive modelling to systematically inform environmental decision-making. Instead, we use decision-theoretic frameworks, return-on-investment analyses, Bayesian Network models.</description>
    </item>
    
    <item>
      <title>Ropensci</title>
      <link>/posts/ropensci/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/ropensci/</guid>
      <description>Problem Replication effort:
There are many sources of error (as to why claim is not supported, or approximate result[significance in same direction, effect size]):
 actual data is not reflected in code files Can‚Äôt match the environment: Missing packages etc, etc, etc  One model of addressing these issues is using Docker:
Docker goes some way to solving this‚Ä¶. BUT: It‚Äôs really hard to get docker up and running - you need specialised knowledge of how to get your code and data etc.</description>
    </item>
    
    <item>
      <title>from Replication Crisis to Credibility Revolution</title>
      <link>/posts/from-replication-crisis-to-credibility-revolution/</link>
      <pubDate>Wed, 14 Nov 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/from-replication-crisis-to-credibility-revolution/</guid>
      <description>Simine Vazire Credibility Revolution ‚Äì 2008 economic paper.
Self-correction Simine‚Äôs meta-science research: How to become more credible science? What does that mean?
Demarcation problem - science diff. from pseudo-science, how? Merton‚Äôs norms: - self-correction - how do you know? What does that mean? How would you design a self-correcting system? what values, priorities to be instilled?
Universalism - claim validity should not depend on status of person making it. Communality - open access, no secrecy.</description>
    </item>
    
    <item>
      <title>updated-literature-workflow</title>
      <link>/posts/updated-literature-workflow/</link>
      <pubDate>Tue, 16 Oct 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/updated-literature-workflow/</guid>
      <description>Capture papers annotations
Highlights workflow Colours for each different type of annotation References to follow up Metadata
Summarise .md and exporting to DEVONthink.
  Organise The two main apps used are Bookends and DEVONthink. The key difference between the material and level of organisation that goes into these two apps is as follows:
 DEVONthink: project / paper specific organisation. Bookends: general organisation, relevant to any writing task.  Even if a subject area keyword is consistent across both Bookends and DEVONthink, DEVONthink will contain only a subset of those in Bookends - i.</description>
    </item>
    
    <item>
      <title>CEBRA-workshop</title>
      <link>/posts/cebra-workshop/</link>
      <pubDate>Thu, 11 Oct 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/cebra-workshop/</guid>
      <description>Personal reflections on the CEBRA-SDM (pest-management climate modelling) workshop, emphasis on reproducibility.
Discussion with JE and JC Did I get what I need from the workshop, is it useful to me?
I‚Äôm going to assist James in collating all the butcher‚Äôs paper. From this I can attempt to generate a roadmap of the numerous subjective judgments people make during SDM. Then I will be able to map onto those decision points potential QRP analogues.</description>
    </item>
    
    <item>
      <title>Wang et al 2018 Researcher Reqeusts for Inappropriate Analysis and Reporting: A U.S. Survey of Consulting Biostatisticians</title>
      <link>/posts/wang-et-al-2018-researcher-reqeusts-for-inappropriate-analysis-and-reporting-a-u-s-survey-of-consulting-biostatisticians/</link>
      <pubDate>Wed, 10 Oct 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/wang-et-al-2018-researcher-reqeusts-for-inappropriate-analysis-and-reporting-a-u-s-survey-of-consulting-biostatisticians/</guid>
      <description>See this twitter post: https://twitter.com/EricTopol/status/1049448246894948352
The list of QRPs that were included in the survey is as follows, [Table 1][@Wang:2018ba]
 Falsify the statistical significance (such as the P value) to support a desired result Change data to achieve the desired outcome (such as the prevalence rate of cancer or another disease) Remove or alter some dta records (observations) to better support the research hypothesis Interpret the statistical findings on the basis of expectations, not the actual results Do not fully describe the treatment under study because protocol was not exactly followed Do not report the presence of key missing data that could bias the results Ignore violations of assumptions because results may change to negative Modify a measurement scale to achieve some desired results rather than adhering to the original scale as validated Report power on the basis of a post hoc calculation, but make it seem like an a priori statement Request to properly adjust for multiple testing when ‚Äúa priori, originally planned secondary outcomes‚Äù are shifted to an ‚Äúa posteriori primary outcome status‚Äù Conduct too many post hoc tests, but purposefully do not adjust alpha levels to make results look more impressive than they really are Remove categories of a variable to report more favourable results Do not mention interim analyses to avoid ‚Äútoo much testing‚Äù Report results before data have been cleaned up and validated Do not discuss the duration of follow-up because it was inconsistent Stress only the significant findings, but underreport nonsignificant ones Do not report the model statistics (including effect size in ANOVA or \(R^2\) in linear regression) because they seemed too small to indicate any meaningful changes Do not show plot because it did not show as strong as an effect as you had hoped  The table illustrates that QRPs with a lower proportion of people who thought the practice was ‚Äúmost severe‚Äù increase in prevalence (general trend).</description>
    </item>
    
    <item>
      <title>open science in applied and use-inspired basic research</title>
      <link>/posts/open-science-in-applied-and-use-inspired-basic-research/</link>
      <pubDate>Mon, 24 Sep 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/open-science-in-applied-and-use-inspired-basic-research/</guid>
      <description>Stokes, D.E. (2011) Pasteur‚Äôs quadrant: Basic science and technological innovation. Brookings Institution PRess.
Pre-registration difficult when doing research outside of traditional confirmatory research, qualitative methods, exploratory research. How to make a priori hypotheses as transparent as possible.
Transparency is not enough. Problem of how to communicate your research to outsiders‚Ä¶ how to ensure that they can make appropriate inferences. Translational value ‚Äì&amp;gt; how do we incorporate practices that maximise this value?</description>
    </item>
    
    <item>
      <title>Meeting 20 September 2018</title>
      <link>/posts/meeting-2018-sep-20/</link>
      <pubDate>Thu, 20 Sep 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-2018-sep-20/</guid>
      <description>Present: HF, LR, EG.
Divying up the Thesis Stepping back after a couple of talks and much RA-ing‚Ä¶ Today we discussed the division of the QRP research material I have been working on in terms of research outputs / papers. We then discussed the overall plan for the thesis, and reflected back on the original plan discussed at the pre-confirmation meeting.
The QRP material is to be divided into two papers:</description>
    </item>
    
    <item>
      <title>Thesis Bootcamp</title>
      <link>/posts/thesis-bootcamp/</link>
      <pubDate>Wed, 19 Sep 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/thesis-bootcamp/</guid>
      <description>Date of the Bootcamp: 19th - 21st October https://gradresearch.unimelb.edu.au/preparing-my-thesis/writing-the-thesis https://gradresearch.unimelb.edu.au/preparing-my-thesis/thesis-with-publication
Please provide a brief description of your research area/interests as relevant to your thesis: 
PhD Title: Transparency and Reproducibility of Decision Support Tools in Ecology and Conservation. This includes fields, such as: meta-research / meta-science, open science, conservation decision-making, structured decision making and decision theory / decision analysis, as well as ecological modelling.
Why would you like to participate in the Thesis Boot Camp?</description>
    </item>
    
    <item>
      <title>Choose your own adventure: researcher degrees of freedom and questionable research practices in ecological modelling for decision support</title>
      <link>/posts/modelling-workflows-researcher-degrees-of-freedom-and-transparency/</link>
      <pubDate>Mon, 03 Sep 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/modelling-workflows-researcher-degrees-of-freedom-and-transparency/</guid>
      <description>Abstract: Initial meta-science research in ecology and evolution suggests that the discipline is not immune to the sorts of reproducibility issues highlighted in other scientific disciplines, such as Psychology and Medicine. A recent study has revealed rates of self-reported Questionable Reserach Practices (QRPs) in ecology and evolution comprable to other disciplines. QRPs include practices such as cherry-picking, p-hacking and hypothesising after results are known (HARKing), and result in low rates of reproducibility, contributing to biased accounts of the subject domain in the body of literature.</description>
    </item>
    
    <item>
      <title>Meeting 23 August</title>
      <link>/posts/meeting-23-august/</link>
      <pubDate>Thu, 23 Aug 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-23-august/</guid>
      <description>Tasks from last week: Develop QRP list across all methods. Figure out what is general between each of the methods. Then come up with a list of QRPs specific to the method under consideration. Also think about the overarching decision / analytic process for each of the methods. Could the QRP occur at multiple points along the workflow / model building pipeline? Sampling protocol - begin writing code, journal selection. Think about elicitation measures, what they could be, and how they could be the same across each of the methods  Other things to discuss today:</description>
    </item>
    
    <item>
      <title>Bayesianism and questionable research practices</title>
      <link>/posts/bayesianism-and-questionable-research-practices/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/bayesianism-and-questionable-research-practices/</guid>
      <description>What are the different model types / applications used in ecology / conservation? what is the process for deriving, evaluating, and reporting these models? At what point in the process might QRPs arise? Can the same QRP arise at different points during the analysis?  Next actions
 read the stopping rules paper I just imported into papers add prior selection / weighting and other qaeco retreat points to the table below can we generalise overarching workflows across methods?</description>
    </item>
    
    <item>
      <title>Simonsohn (2014) </title>
      <link>/posts/simonsohn-2014/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/simonsohn-2014/</guid>
      <description>Relationship to frequentist analyses, and the potential for P-hacking Simsonohn (2014) ran two computational experiments looking at the effects of p-hacking practices on the chance of a type I error for both Bayesian confidence intervals and Bayes Factors. He compared the Bayesian methods to the frequentist methods for each.
Bayesian confidence intervals are mathematically equivalent to frequentist confidence intervals. The only real difference is that their philosophical interpretation is different (and under both inference frameworks, normality is assumed).</description>
    </item>
    
    <item>
      <title>Meeting 16 August 2018</title>
      <link>/posts/meeting-16-august-2018/</link>
      <pubDate>Sat, 18 Aug 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-16-august-2018/</guid>
      <description>Survey Sampling Design FF queried elicitation of non-experts about the prevalence of QRPs across methods they were familiar with, but hadn‚Äôt implemented themselves. Encouraged solid justification for doing this. The only reason that comes to mind for her is if increasing the sample size is the aim. But otherwise, QRP research seems to show that people are particularly forthcoming when it comes to self-reporting. So any arguments about issues around self-reporting affecting the prevalence estimates are basically moot.</description>
    </item>
    
    <item>
      <title>Morgan et al 2017 Use (and abuse) of expert elicitation in support of decision making for public policy</title>
      <link>/posts/morgan-et-al-2017-use-and-abuse-of-expert-elicitation-in-support-of-decision-making-for-public-policy/</link>
      <pubDate>Tue, 14 Aug 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/morgan-et-al-2017-use-and-abuse-of-expert-elicitation-in-support-of-decision-making-for-public-policy/</guid>
      <description>Morgan (2014) present a review of expert elicitation methods for decision support in public policy. I reviewed this paper looking for information on how to design my methods for the expert eliciation of judgments about the consequences of particular research practices on the risk of a type I error in models used in decision support in ecology and conservation.
 I draw on relevant literature and 35 y of personal experience in designing and conducting substantively detailed expert elicitations, to suggest when it does and does not make sense to perform elicitations, how they should be designed and conducted, and how I believe the results should and should not be used.</description>
    </item>
    
    <item>
      <title>RSE‚Äôs across the world: now in Australia</title>
      <link>/posts/rse-s-across-the-world-now-in-australia/</link>
      <pubDate>Tue, 14 Aug 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/rse-s-across-the-world-now-in-australia/</guid>
      <description></description>
    </item>
    
    <item>
      <title>2018-09-08 meeting QRP survey design</title>
      <link>/posts/meeting-qrp-survey-design/</link>
      <pubDate>Wed, 08 Aug 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-qrp-survey-design/</guid>
      <description>Themis, Ethics
 [x] Location / public / private [x] Named Researcher credentials and experience  RIOT accreditation counts for the training question. Just give one sentence spiel for the other questions. Survey Design Estimating Prevalence and Risk of QRPs \(Risk = Likelihood \times Consequence\)
Risk
% papers or researchers engaging in the practice.
If researchers:
 can compare the number of estimated vs.¬†self-reported? Some interesting questions about whether self reporters estimate the prevalence to be greater than non-self reporters, is the self reported rate lower than the estimated rate?</description>
    </item>
    
    <item>
      <title>Dormann et al (2018) Biotic interactions in species distribution modelling\: 10 questions to guide interpretations and avoid false conclusions</title>
      <link>/posts/dormann-et-al-2018-biotic-interactions-in-species-distribution-modelling-10-questions-to-guide-interpretations-and-avoid-false-conclusions/</link>
      <pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/dormann-et-al-2018-biotic-interactions-in-species-distribution-modelling-10-questions-to-guide-interpretations-and-avoid-false-conclusions/</guid>
      <description>Problem The authors aim to address the problem of false conclusions arisng during inference of joint species distribution models ‚Äì specifically, false conclusions of biotic interactions.
Approach The authors conduct a review of joint species distribution modelling to identify (from caveats and other issues ear-marked in the source papers) potential factors that confound interpretation of analyses. Next, they develop a series of questions that can be asked by the analyst and also the reviewer to guide interpretation of conclusions ‚Äì are the conclusions about biotic interactions plausible?</description>
    </item>
    
    <item>
      <title>New Perspectives in Statistics Education</title>
      <link>/posts/new-perspectives-in-statistics-education/</link>
      <pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/new-perspectives-in-statistics-education/</guid>
      <description>Upcoming events: Statistical Society of Australia (SSA), Biostatistics bonanza. August 23.
Sue Finch: ‚ÄúBack to basics? Identifying educational needs through statistical consulting‚Äù People who come to consulting come with real need - come with an applied problem. How can we use this to inform new generation of statistical training for researchers?
Break down research cycle using PPDAC cycle used within statistical education (Wild and Pfannkuch). Process of statistical thinking when carrying out a statistical inquiry.</description>
    </item>
    
    <item>
      <title>Baranyi and da Silva (2017) The use of predictive models to optimize risk of decisions</title>
      <link>/posts/baranyi-and-da-silva-2017-the-use-of-predictive-models-to-optimize-risk-of-decisions/</link>
      <pubDate>Wed, 25 Jul 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/baranyi-and-da-silva-2017-the-use-of-predictive-models-to-optimize-risk-of-decisions/</guid>
      <description>Application domain: Microbiology decision support for predicting food borne Bacteria growth and reduce the need for microbiological testing. Approach/framework: risk assessment and decision-analytic framework.
Aims and objectives of the paper:
 The focus of this paper is not the above interpreted risk, assigned to an a-posteriori event, but the risk of an a-priory decision, that we also call choice or bet in what follows.
  In this paper we explain, backed by examples, why predictive models should be used in combination with a cost-bene fit assessment.</description>
    </item>
    
    <item>
      <title>Retreat QRP session</title>
      <link>/posts/retreat-qrp-session/</link>
      <pubDate>Fri, 20 Jul 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/retreat-qrp-session/</guid>
      <description>Summary and purpose of the workshop: We ran a workshop where we hosted small discussions attempting to propose questionable research practices that arise in ecological and conservation research using non-frequentist and/or non hypothetico-deductive inquiry.
The purpose of the workshop was two-fold:
To bring awareness to our research group of QRPs for the types of work relevant to the group, and to consider how reproducibility issues might affect us, even if reproducibility research seems irrelevant.</description>
    </item>
    
    <item>
      <title>John Blischak reproducibility and workflowr</title>
      <link>/posts/john-blischak-reproducibility-and-workflowr/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/john-blischak-reproducibility-and-workflowr/</guid>
      <description>Institutional road blocks against full reproducibility - methods sections are insufficient. But good software practice is helpful for future you, your labmates when you leave.
Lowndes et al (2017) Peng et al (2011)
Strategies for computational repro Record computing environment  sessionInfo() ## R version 3.5.1 (2018-07-02) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS 10.14.1 ## ## Matrix products: default ## BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_AU.</description>
    </item>
    
    <item>
      <title>Seaman &amp; Weber (2015) Undisclosed Flexibility in Computing and Reporting Structural Equation Models in Communication Science.</title>
      <link>/posts/seaman-c-s-weber-r-2015-undisclosed-flexibility-in-computing-and-reporting-structural-equation-models-in-communication-science/</link>
      <pubDate>Tue, 10 Jul 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/seaman-c-s-weber-r-2015-undisclosed-flexibility-in-computing-and-reporting-structural-equation-models-in-communication-science/</guid>
      <description>Summary This paper is a systematic review (or ‚Äòmethodological review‚Äô in their tersm) of both QRPs and bad modelling practice in structural equation modelling within the field of communication. They don‚Äôt use the term ‚ÄòQuestionable Research Practices‚Äô, however, they do explicitly look at practices falling under the QRP banner, including cherry-picking, HARKing, and researcher degrees of freedom. Importantly, this paper is really useful to me because they examine these questionable research practices in a modelling framework outside of the non-hypothetico-deductive scientific model.</description>
    </item>
    
    <item>
      <title>Schmolke et al (2010) Ecological models supporting environmental decision making: a strategy for the future</title>
      <link>/posts/schmolke-et-al-2010-ecological-models-supporting-environmental-decision-making-a-strategy-for-the-future/</link>
      <pubDate>Tue, 26 Jun 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/schmolke-et-al-2010-ecological-models-supporting-environmental-decision-making-a-strategy-for-the-future/</guid>
      <description></description>
    </item>
    
    <item>
      <title>de Vos Are Environmental Models Transparent and Reproducible?</title>
      <link>/posts/de-vos-are-environmental-models-transparent-and-reproducible/</link>
      <pubDate>Wed, 20 Jun 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/de-vos-are-environmental-models-transparent-and-reproducible/</guid>
      <description>Problem: Why is transparency and reproducibility of environmental models important? Transparency and reproducibility are quintessential for facilitating assessment of model quality and suitability by both peer-reviewers, readers, and future users:  Page 1, 2018-06-20:  Environmental models are in fact applications of shared theories on how real-world systems are functioning.
 Because ‚ÄúEnvironmental models are in fact applications of shared theories on how real-world systems are functioning‚Äù, it is essential that ‚Äúthe underlying scientific theories they need to be evaluated and discussed among peers.</description>
    </item>
    
    <item>
      <title>QRPs Study Planning</title>
      <link>/posts/qrps-study-planning/</link>
      <pubDate>Thu, 14 Jun 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/qrps-study-planning/</guid>
      <description>QRPs for non-hypothesis testing research in Ecology and Conservation Decision Making Problem and Background:
The reproducibility literature has focused exclusively on hypothesis-testing, whether that be Bayesian or frequentist. This also applies to initial research focusing on ecology and evolution. However, Fidler (2016) correctly identifies that in applied ecological research, particularly in conservation science, non-hypothesis testing methods, such as decision-theory, cost-effectiveness analysis, optimization and other scientific computing methods are common. These approaches come with their own set of reproducibility issues.</description>
    </item>
    
    <item>
      <title>Advisory Committee Meeting</title>
      <link>/posts/advisory-committee-meeting/</link>
      <pubDate>Mon, 04 Jun 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/advisory-committee-meeting/</guid>
      <description>Chapter 2, QRPs Scope Trying to cover the scope of the entire decision process might be too large for just one chapter. Just examining QRPs for system modelling is quite a task. PV suggested restricting the focus to decision tools and focussing on one application area, such as conservation planning / reserve design. This would also give more traction and uptake among ecologists. Conservation planning isn&amp;rsquo;t using the term &amp;lsquo;reproducibility&amp;rsquo; to describe their problems.</description>
    </item>
    
    <item>
      <title>Arguments against the existance and extent of the reproducibility crisis</title>
      <link>/posts/arguments-against-the-existance-and-extent-of-the-reproducibility-crisis/</link>
      <pubDate>Fri, 25 May 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/arguments-against-the-existance-and-extent-of-the-reproducibility-crisis/</guid>
      <description>Despite a growing body of large-scale meta-analyses across many different disciplines, debate as to whether there is a ‚Äúcrisis‚Äù persists. Fanelli et al. (2018) use a failed replication of a large-scale meta-analysis to argue that the ‚Äúcrisis‚Äù is mistaken, and should instead be re-branded as a narrative of ‚Äúepochal changes and empowerment of science‚Äù (Jamieson 2018). In a ‚Äòpost-truth‚Äô era of ‚Äòalternative-facts‚Äô, how scientists communicate research on the robustness of science and its self-correcting mechanisms is certainly important (Sutherland and Wordley 2017).</description>
    </item>
    
    <item>
      <title>PhD Research Proposal: Reproducibility and Transparency of Decisions in Ecology and Conservation</title>
      <link>/posts/research_proposal/</link>
      <pubDate>Wed, 23 May 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/research_proposal/</guid>
      <description>Keywords:
 conservation decision-making ecology reproducibility structured decision-making  Introduction Successful biodiversity conservation and management is underpinned by effective and robust decision-making (Mukherjee et al. 2018). Decision-makers are tasked with allocating limited resources in the face of uncertainty about the effectiveness of alternative management interventions, and incomplete or inadequate scientific information. Moreover, environmental decisions often must be made in complex socio-economic and political contexts, with multiple stakeholders and multiple and/or competing objectives.</description>
    </item>
    
    <item>
      <title>proposal out-takes</title>
      <link>/posts/proposal_outtakes/</link>
      <pubDate>Tue, 22 May 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/proposal_outtakes/</guid>
      <description>Unpacking what this (‚Äúreproducibility issues‚Äù) means ‚Ä¶ what do we need to know? what is my task a. how to measure the likely reproducibility of a study b. what is the function / role of different types of replications in terms of what they tell us about the broader state of the literature (validity, generalisations) c.
how widespread the reproducibility issues identified in part I. The work from the first aim will help to inform the scoping rules and coding criteria for the systematic review.</description>
    </item>
    
    <item>
      <title>Decision Science Vocabulary</title>
      <link>/posts/decision_science_vocabulary/</link>
      <pubDate>Wed, 16 May 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/decision_science_vocabulary/</guid>
      <description>Decision Making: &amp;quot; p.56: For the purposes of this paper, we define decision-making as the process of identifying options and selecting a feasible solution, based on evidence combined with the decisionmaker‚Äôs values and experience (DeFries &amp;amp; Nagendra, 2017). ‚Äì Highlighted 21 May 2018&amp;quot; (Mukherjee et al. 2018)
When is a tool a tool or a system? See heading ‚Äúdecision support systems‚Äù in (Dicks, Walsh, and Sutherland 2014) Dicks, L. V., Walsh, J.</description>
    </item>
    
    <item>
      <title>Fraser et al 2018 QRPs in Ecology and Evolution</title>
      <link>/posts/fraser-et-al-2018-qrps-in-ecology-and-evolution/</link>
      <pubDate>Tue, 15 May 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/fraser-et-al-2018-qrps-in-ecology-and-evolution/</guid>
      <description>Fraser, H. S., Parker, T. H., Nakagawa, S., Barnett, A., Fidler, F. (2018) Questionable Research Practices in Ecology and Evolution. doi: 10.17605/OSF.IO/AJYQG.
‚ÄúTransformation process‚Äù of science communication is susceptible to confusion and corruption, has triggered both reflection and meta-research in other disciplines.
Forstmeier et al [8]:
Individual research practice is embedded in a broader culture, and promoite conditions of publication bias and type 1 errors. ‚ÄòQuestionable research practices‚Äô are fostered under conditions of publication bias, inflating false postive rates in the literature.</description>
    </item>
    
    <item>
      <title>Retreat Reproducibility Session</title>
      <link>/posts/retreat-reproducibility-session/</link>
      <pubDate>Mon, 14 May 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/retreat-reproducibility-session/</guid>
      <description>Session Planning Focus: Reproducibility in practice - QRPs.
Session aim: To help spread awareness among Qaecologists and Cebranalysts about reproducibility issues in our research practices. And then possibly provide people with the tools / solutions to overcome some of these issues.
Format: not a lecture, not an unstructured discussion.
Length 90 minutes.
Introduction: 15 minutes Introductory talk with a few slides . Led by Fiona and Hannah.
Intro by Fiona, perhaps talking about why reproducibility is important to us as ecologists, the state of reproducibility in eco/evo, an in the context of other dsciplines?</description>
    </item>
    
    <item>
      <title>Gardner et al. 2018 Decision Complacency and Conservation Planning</title>
      <link>/posts/gardner-et-al-2018-decision-complacency-and-conservation-planning/</link>
      <pubDate>Wed, 09 May 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/gardner-et-al-2018-decision-complacency-and-conservation-planning/</guid>
      <description>Gardner et al. (2018) add to knowledge-doing gap literature by defining and exemplifying what they call ‚ÄúDecision Complacency‚Äù
 The non-use of evidence or systematic processes to make decisions.
 Contextualising decision complacency in the knowledge-doing gap:
Researcher-practitioner divide: the case where researchers do not meet the needs of practitioners such that the information provided by conservation scientists does not allow decision-makers or practitioners to make sufficiently evidence-based decisions Evidence Complacency: Sutherland and Wordley (2017) describe a different angle of the researcher-practitioner divide where practitioners don‚Äôt use or seek available evidence, and/or don‚Äôt test the impact of their actions.</description>
    </item>
    
    <item>
      <title>Cullina et al 2018 Navigating the unfolding open data landscape in ecology and evolution</title>
      <link>/posts/cullina-et-al-2018-navigating-the-unfolding-open-data-landscape-in-ecology-and-evolution/</link>
      <pubDate>Fri, 13 Apr 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/cullina-et-al-2018-navigating-the-unfolding-open-data-landscape-in-ecology-and-evolution/</guid>
      <description>The open data movement has the capacity to provide new and powerful insights into complex systems, in ecology and evolution. However, in ecology and evolution there has not been great uptake / implementation of open data to the extent seen in other disciplines (e.g.¬†medicine, climate sciences).
Why open data?
 identify broader eco evo processes across space, time, species reanalysing data using new statistical approaches error checking using existing data to answer new questions era of the Anthropocene: large, complicated questions with high degree of uncertainty requires combined data from multiple sources, and multidsciplinary data synthesis.</description>
    </item>
    
    <item>
      <title>Nakagawa and Parker 2015</title>
      <link>/posts/nakagawa-and-parker-2015/</link>
      <pubDate>Thu, 12 Apr 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/nakagawa-and-parker-2015/</guid>
      <description>Why do we replicate? Assess the validity of prior findings probe the generality of those findings   Levels of replication Exact (also known as ‚Äúdirect‚Äù): highest fidelity to the original work. But in ecology, usually can only be ‚Äòclose‚Äô replications. Partial: there is a spectrum of partial replications, from close to limited. These have slight procedural differences. Conceptual: uses distinctly different study designs to test the same hypotheses. Quasi-replication (cross-species or system)   Assessing validity  Probing generality Conceptual replications: when results concur, we can define generality.</description>
    </item>
    
    <item>
      <title>meeting april 12 2018</title>
      <link>/posts/meeting-april-12-2018/</link>
      <pubDate>Thu, 12 Apr 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-april-12-2018/</guid>
      <description>Planning the projects and the scope of the Phd (and the format for the thesis):
 Perfectly acceptable to have disparate projects / papers comprising the thesis, and bound together with a good introduction and conclusion. Don‚Äôt have to choose between different projects.  Good to try and sit with that tension, and not having to resolve it by having a neat / tightly fitting narrative thesis.
Hannah: working on structured decision making tool with Libby.</description>
    </item>
    
    <item>
      <title>About me and this electronic notebook</title>
      <link>/about/</link>
      <pubDate>Tue, 03 Apr 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/about/</guid>
      <description>I am a PhD student at the Quantitative and Applied Ecology Group (QAECO) and Centre of Excellence for Biosecurity and Risk Analysis (CEBRA), University of Melbourne. This is my research notebook for all things related to my PhD.
My research interests include:
 Ecological modelling Structured Decision Making Plant ecology vegetation management reproducibility data science R  I&amp;rsquo;ve used the template from https://github.com/sirselim/electronic_lab_notebook to set up this electronic lab notebook using blogdown and the static site generator hugo.</description>
    </item>
    
    <item>
      <title>meeting</title>
      <link>/posts/meeting/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting/</guid>
      <description> Investigating appropriate systematic review methodologies Developing a framework / list of non-NHST reproducibility issues (QRP&amp;rsquo;s and other sources of bias) for decision-support tools &amp;ndash;&amp;gt; informing the coding criteria for systematic review    Fiona link.l  </description>
    </item>
    
    <item>
      <title>Fidler 2017 Metaresearch in ecology</title>
      <link>/posts/fidler-2017-metaresearch-in-ecology/</link>
      <pubDate>Wed, 21 Mar 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/fidler-2017-metaresearch-in-ecology/</guid>
      <description>Fidler, F., Chee, Y. E., Wintle, B. A., Burgman, M. A., McCarthy, M. A., Gordon, A. (2017) Metaresearch for Evaluating Reproducibility in Ecology and Evolution. BioScience doi: 10.1093/biosci/biw159.
Demonstrate that ecology and evolution as disciplines are at risk of a having low rates of reproducibility, aka a &amp;lsquo;reproducibility crisis&amp;rsquo; as others have termed it. The paper sets out to identify the different ways in which ecology is likely to have a reproducibility problem.</description>
    </item>
    
    <item>
      <title>bioinformatics workshop dockerisation</title>
      <link>/posts/bioinformatics-workshop-dockerisation/</link>
      <pubDate>Wed, 21 Mar 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/bioinformatics-workshop-dockerisation/</guid>
      <description>Slides are here: http://melbournebioinformatics.github.io/MelBioInf_docs/tutorials/docker/media/index.html#47
Docker: libraries and operating system included as well (as application). ALl dependencies distributed. AND docker containers are cross-platform. == Portable. Distributable: can store images on the docker cloud.
Docker containers can&amp;rsquo;t access host-system&amp;rsquo;s files (good for security), but limits some use-cases (especially where command line utilities used).
Docker containers are very lightweight (no overhead like what virtual machines have). Docker can share libraries&amp;hellip; so if have 3 containers running ubuntu, they all share this code, whereas VM&amp;rsquo;s have to have 3 versions, one for each instance.</description>
    </item>
    
    <item>
      <title>reproducibility for decision support tools</title>
      <link>/posts/reproducibility-for-decision-support-tools/</link>
      <pubDate>Wed, 21 Mar 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/reproducibility-for-decision-support-tools/</guid>
      <description>I&amp;rsquo;ve set aside this document for developing a parallel framework of reproducibility issues not just outside of NHST, but particular to Decision Support Tools in ecology and conservation.
WHY? Because the majority of work addressing reproducibility in and outside of ecology has focused on hypothesis testing (NHST, predominantly). And non-NHST methods are important tools in the Decision Support toolbox for conservation science and applied ecology.
From this, I hope to: a) develop the coding criteria for the systematic review b) propose some sort of gold-standard protocol for developing reproducible decision support tools</description>
    </item>
    
    <item>
      <title>meeting 15 March 2018</title>
      <link>/posts/meeting-15-march-2018/</link>
      <pubDate>Thu, 15 Mar 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-15-march-2018/</guid>
      <description>Libby, Hannah present.
Exploring systematic review methods Add my notes from CJ meeting here.
Also see: BES - will be discussed in coding club / reading club. SER (Society of ecological restoration) -&amp;gt; Australian Chapter, SERA. Other disciplines where science / evidence is used in making decision s(Ecotoxicology / Biosecurity).
Authors who have worked on systematic reviews in ecology (@TODO): - Catherine Pickering - Robin Hale - W J Sutherland</description>
    </item>
    
    <item>
      <title>reading club reproducibility</title>
      <link>/posts/reading-club-reproducibility/</link>
      <pubDate>Thu, 15 Mar 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/reading-club-reproducibility/</guid>
      <description>BES Reproducibility guidelines.
Good for YOU, and for reproducibility.
Uptake in education: Fiona new reproducibility subject at the University.
Setting up a project / programming  Archive old papers + code: local folder (Nick) RANDOM SEED&amp;hellip; forgetting to set. Compounded by long run-times and large file-sizes.  Accessibility&amp;hellip; Barriers to startign work on reproducibility, but also, what are the bare minimum standards&amp;hellip; -&amp;gt; Little changes each new time.
Statistical abstinence vs.</description>
    </item>
    
    <item>
      <title>systematic review methodologies for conservation and ecology</title>
      <link>/posts/systematic-review-methodologies-for-conservation-and-ecology/</link>
      <pubDate>Thu, 15 Mar 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/systematic-review-methodologies-for-conservation-and-ecology/</guid>
      <description>Systematic Review Methods Nakagawa and Poulin [-@Nakagawa:2012fl] recommend following the PRISMA statement, at least for meta-analyses in ecology and evolution.
PRISMA
Checklist here: http://www.prisma-statement.org/documents/PRISMA%202009%20checklist.pdf
Cochrane Review
Manual broken down into two phases of the review: 1. Developing Protocol of the review 2. Conducting Review
Writing review protocol - Formulating review questions, predefining objectives. - Medicine focused, emphasis on reporting adverse effects, on consumer needs - Choosing &amp;lsquo;outcomes&amp;rsquo;of interest (Mandatory). Assessing risk of bias of studies included in the review.</description>
    </item>
    
    <item>
      <title>French 2012 meta-analysis for expert judgment</title>
      <link>/posts/french-2012-meta-analysis-for-expert-judgment/</link>
      <pubDate>Tue, 06 Mar 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/french-2012-meta-analysis-for-expert-judgment/</guid>
      <description>French, S. (2012) Expert Judgment, Meta-analysis, and Participatory Risk Analysis. Decision Analysis. 9, 119‚Äì127.
Problem / background and paper goals Page 2 [@French:2012di] describes three types of expert elicitation problems. The third forms the focus of the paper:
 The expert problem: where the decision-maker does not have the domain knowledge and elicits judgments from a group of experts. The group decision problem: where the expert group itself is jointly responseible for the decision.</description>
    </item>
    
    <item>
      <title>meeting Fiona Hannah 1st March 2018</title>
      <link>/posts/meeting-fiona-hannah-1st-march-18/</link>
      <pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-fiona-hannah-1st-march-18/</guid>
      <description>To date:
Have been trying to determine the scope of the project. Want to look at the reproducibility of decision support tools
 what elements of existing reproducibility literature apply to this context?
 do we need a new set of criteria? Much of the repro literature especially in ecology seems to be focused on NHST, but this statistical tool is rarely used in decision science, instead it might often rely on the outputs of other studies that utilise them.</description>
    </item>
    
    <item>
      <title>Meeting Hannah</title>
      <link>/posts/meeting-hannah/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-hannah/</guid>
      <description>See Steve&amp;rsquo;s guidelines around meta-analysis from medicine. Hannah&amp;rsquo;s criteria. Conservation Biology guidelines. Guidelines / checkpoints are just around transparency. No actual checking of reproducibility.
How do decisions vs. models differ? What is particular about my problem context? values, preferences. Process vs. decision model - problem is often split into two. Decision tools as models more complex, involve not just a model of the system / domain (including decision elements), but capturing objectives, alternatives, eliciting expert judgment, involving many stakeholders.</description>
    </item>
    
    <item>
      <title>PhD Timeline and Milestones</title>
      <link>/posts/phd_timeline/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/phd_timeline/</guid>
      <description>Timeline &amp;lt;iframe src=‚Äúhttps://egouldo.shinyapps.io/shiny_phd_timeline/‚Äù style = &amp;quot;border: none; width: 900px; height: 1000px&amp;gt;
 Milestones Milestones are documented in the RHD manual, page 4: https://app.lms.unimelb.edu.au/bbcswebdav/pid-6166800-dt-content-rid-24849943_3/orgs/COM_01654/RHD%20Handbook%20v%202017%2008%2016%20LMS%20version%202.pdf
Candidature and Confirmation: Probationary Candidate: You start your PhD as a probationary candidate and within 12 months (we recommend the ideal time of 9 to 10 months) you will go through the confirmation procedure, formalising your candidature. Purpose of Confirmation: The main purpose of the confirmation process is to determine if you have developed a detailed research plan together with your supervisor(s), to assess whether this research plan meets the requirements of the degree, and to assess if adequate progress has been made.</description>
    </item>
    
    <item>
      <title>Madin (2007) Advancing ecological research with ontologies</title>
      <link>/posts/madin-2007-advancing-ecological-research-with-ontologies/</link>
      <pubDate>Sat, 24 Feb 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/madin-2007-advancing-ecological-research-with-ontologies/</guid>
      <description>(Madin et al. 2008)
Why are ontologies relevant to ecology? Issue of effectively locating scientific data is hampered because our current approaches for describing it rely on the ‚Äúad hoc use of user-supplied keywords, and do not ensure that such terms are defined and used consistently.‚Äù The same is true when searching for relevant data, ‚Äúusers supply their own search terms, which are then matched against keywords assigned to datasets‚Äù. Ecology is particularly prone to this problem, and many terms often have multiple and variable meanings in different contexts.</description>
    </item>
    
    <item>
      <title>meeting</title>
      <link>/posts/meeting/</link>
      <pubDate>Thu, 22 Feb 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting/</guid>
      <description> Activities in the last week  Trying to map out the landscape of reproducibility, in particular, within ecology.  What is the magnitude of the reproducibility crisis, do people even think we have one? What&amp;rsquo;s being done? Mostly focused on efforts by individuals or research groups, as well as institutional efforts, particularly emerging in the bioinformatics discipline and focusing on computational analysis workflows and data management.
 Is there really a differnce  </description>
    </item>
    
    <item>
      <title>Hart - Towards a more reproducible ecology</title>
      <link>/posts/hart-towards-a-more-reproducible-ecology/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/hart-towards-a-more-reproducible-ecology/</guid>
      <description>Borregaard, M. K., Hart, E. M. (2018) Towards a more reproducible ecology. httpwww.ecography.orgblogtowards-more-reproducible-ecology, 1‚Äì9.
This is an editorial intro to the special edition of ecography dedicated to reproducible methods in ecology..
Page 1 Page 1, Red, Text, 2018-02-20: State of ecological research and analyses has changed.
Page 1, Red, Highlight, 2018-02-20:  A new paradigm has emerged, where individual scientists download, curate and share large amounts of data and analyse it using reproducible software packages and scripts written in languages such as R, Python and Julia.</description>
    </item>
    
    <item>
      <title>reproducibility criteria</title>
      <link>/posts/reproducibility-criteria/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/reproducibility-criteria/</guid>
      <description>I need to start thinking about how we define reproducibility for a) ecological models b) ecological models in the context of decision support.
Reviewing Fiona&amp;rsquo;s article on metaresearch on ecology would be a good place to start thinking about reproducibility in ecology.
-&amp;gt; Reproducibility in ecology&amp;hellip; why important? &amp;ldquo;the inherent complexity of the inference chain needed to advance ecology as well as the importance of ecological results to challenges important to society&amp;rdquo; https://eco.</description>
    </item>
    
    <item>
      <title>Guerrero et al 2017 Using SDM to set restoration objectives</title>
      <link>/posts/guerrero-et-al-2017-using-sdm-to-set-restoration-objectives/</link>
      <pubDate>Mon, 19 Feb 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/guerrero-et-al-2017-using-sdm-to-set-restoration-objectives/</guid>
      <description>Guerrero, A. M., Shoo, L., Iacona, G., Standish, R. J., Catterall, C. P., Rumpff, L., de Bie, K., White, Z., Matzek, V., Wilson, K. A. (2017) Using structured decision-making to set restoration objectives when multiple values and preferences exist. Restoration Ecology. 25, 858‚Äì865.
Problem: achieving restoration targets is impeded by difficulty in identifying and working towards targets, because objective setting is beset by multiple / conflicting values and preferences, and there are often time-lags in a restoration action and its desired outcome.</description>
    </item>
    
    <item>
      <title>meeting Feb 15 2018</title>
      <link>/posts/meeting-feb-15-2018/</link>
      <pubDate>Thu, 15 Feb 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-feb-15-2018/</guid>
      <description>activities -&amp;gt; working towards the research proposal -&amp;gt; also on first chapter
Reading: - trying to identify difficulties / issues in modelling applied ecological problems in general - e.g. projecting performance of conservation actions, building the evidence base in restoration ecology as new techniques emerge.
-&amp;gt; aims, trying to identify why reproducibility is important for ecological models / DSTs
defining reproducibility for ecological models (still need to justify this)</description>
    </item>
    
    <item>
      <title>McPherson et al 2018 A simulation tool to scrutinise the behaviour of functional diversity metrics</title>
      <link>/posts/mcpherson-et-al-2018-a-simulation-tool-to-scrutinise-the-behaviour-of-functional-diversity-metrics/</link>
      <pubDate>Thu, 18 Jan 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/mcpherson-et-al-2018-a-simulation-tool-to-scrutinise-the-behaviour-of-functional-diversity-metrics/</guid>
      <description>\cite{MEE3:MEE312855}
Problem
More and more indices of diversity are created with time. Accurately quantifying functional diversity is important because we want to know how biodiversity loss affects ecosystem functioning.
Functional diversity is the &amp;ldquo;values and range of functionally important traits in a community&amp;rdquo;.
The authors describe four dimensions to functional diversity:
 functional richness evenness divergence redundancy  And they each characterise how organisms interact with ecosystem functioning.
Although the choice of index should be guided by the functional diversity component of interest, there are multiple indices available for each component, and then there are synthetic indices that summarise all four components as a whole.</description>
    </item>
    
    <item>
      <title>Matzek et al (2017) Emerging approaches to successful ecologicall restoration</title>
      <link>/posts/matzek-et-al-2017-emerging-approaches-to-successful-ecologicall-restoration/</link>
      <pubDate>Thu, 21 Dec 2017 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/matzek-et-al-2017-emerging-approaches-to-successful-ecologicall-restoration/</guid>
      <description>Matzek, V., Gornish, E. S., Hulvey, K. B. (2017) Emerging approaches to successful ecological restoration: five imperatives to guide innovation (eds E. Gornish, V. Matzek, &amp;amp; K. Hulvey). Restoration Ecology. 25, S110‚ÄìS113.
New techniques, approaches, and technologies are emerging and being applied in habitat restoration. This is because restoration goals are shifting towards resilience and dynamism, and because the need for efficient resource use is of increasing concern.
The paper serves as an introduction / review to the special issue of the journal.</description>
    </item>
    
    <item>
      <title>first chapter</title>
      <link>/posts/first-chapter/</link>
      <pubDate>Mon, 18 Dec 2017 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/first-chapter/</guid>
      <description>Libby has suggested an idea for the first chapter. It would be a data-based review of reproducibility issues facing decision support tools and ecological models. It would require not simply applying existing criteria for reproducibility, but would require generating criteria appropriate to DST&amp;rsquo;s and ecological models. Maybe some existing criteria apply. Maybe some don&amp;rsquo;t.
First chapter initial steps:
 identify why reproducibility is important for ecological models / decision support tools Generate a list of reproducibility criteria: - review issues facing devt of ecological models - review literature on reproducibility in ecology / conservation in general Generate a set of DST&amp;rsquo;s / models to apply the list to Figure out a way of scoring the models Apply the list and score the models  Questions:</description>
    </item>
    
    <item>
      <title>Law et al. (2017) Biol Con</title>
      <link>/posts/law-et-al-2017-biol-con/</link>
      <pubDate>Fri, 15 Dec 2017 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/law-et-al-2017-biol-con/</guid>
      <description>Law, E. A., Ferraro, P. J., Arcese, P., Bryan, B. A., Davis, K., Gordon, A., Holden, M. H., Iacona, G., Martinez, R. M., McAlpine, C. A., Rhodes, J. R., Sze, J. S., Wilson, K. A. (2017) Projecting the performance of conservation interventions. BIOC doi: 10.1016/j.biocon.2017.08.029.
Problem: Projecting the performance of conservation interventions Successful decision-making for environmental management requires reliable evidence for both the performance and efficacy of proposed conservation actions.</description>
    </item>
    
    <item>
      <title>first post</title>
      <link>/posts/first-post/</link>
      <pubDate>Wed, 13 Dec 2017 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/first-post/</guid>
      <description>Readings: Reproducibility ‚Äì how to define for this context. Ecology / decision support tools.
Reproducibility of ecological models used for decision support tools.
Interested in the sorts of decisions that we make as modellers‚Ä¶ e.g. what performance measures do we use, there are so many different ways of valuing the objectives. And depending on which measure you use, you might judge the outcomes of each of the different strategies under consideration differently‚Ä¶.</description>
    </item>
    
    <item>
      <title>QRP and Biases Roadmap</title>
      <link>/posts/qrp_roadmap/</link>
      <pubDate>Wed, 15 Feb 2017 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/qrp_roadmap/</guid>
      <description>Goal I want to generate a ‚Äúroadmap‚Äù of the sources of bias and questionable research practices (QRPs) that I think are frequently encountered when developing D in applied ecology / conservation. These biases will reduce the reproducibility of of a given decision support tool. Identifying where in the DST development process particular biases are likely to occur should serve as a launching point for proposing solutions towards minimising their occurrence and therefore increasing the reproducibility of DSTs.</description>
    </item>
    
  </channel>
</rss>