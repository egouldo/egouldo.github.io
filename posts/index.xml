<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Electronic Lab Notebook</title>
    <link>/posts/</link>
    <description>Recent content in Posts on Electronic Lab Notebook</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>elise.gould@unimelb.edu.au (Elise Gould)</managingEditor>
    <webMaster>elise.gould@unimelb.edu.au (Elise Gould)</webMaster>
    <copyright>(c) 2018 -- All rights reserved.</copyright>
    <lastBuildDate>Wed, 08 Aug 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>2018-09-08 meeting QRP survey design</title>
      <link>/posts/meeting-qrp-survey-design/</link>
      <pubDate>Wed, 08 Aug 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-qrp-survey-design/</guid>
      <description>Themis, Ethics
 [x] Location / public / private [x] Named Researcher credentials and experience  RIOT accreditation counts for the training question. Just give one sentence spiel for the other questions. Survey Design Estimating Prevalence and Risk of QRPs \(Risk = Likelihood \times Consequence\)
Risk
% papers or researchers engaging in the practice.
If researchers:
 can compare the number of estimated vs. self-reported? Some interesting questions about whether self reporters estimate the prevalence to be greater than non-self reporters, is the self reported rate lower than the estimated rate?</description>
    </item>
    
    <item>
      <title>Dormann et al (2018) Biotic interactions in species distribution modelling\: 10 questions to guide interpretations and avoid false conclusions</title>
      <link>/posts/dormann-et-al-2018-biotic-interactions-in-species-distribution-modelling-10-questions-to-guide-interpretations-and-avoid-false-conclusions/</link>
      <pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/dormann-et-al-2018-biotic-interactions-in-species-distribution-modelling-10-questions-to-guide-interpretations-and-avoid-false-conclusions/</guid>
      <description>Problem The authors aim to address the problem of false conclusions arisng during inference of joint species distribution models – specifically, false conclusions of biotic interactions.
Approach The authors conduct a review of joint species distribution modelling to identify (from caveats and other issues ear-marked in the source papers) potential factors that confound interpretation of analyses. Next, they develop a series of questions that can be asked by the analyst and also the reviewer to guide interpretation of conclusions – are the conclusions about biotic interactions plausible?</description>
    </item>
    
    <item>
      <title>New Perspectives in Statistics Education</title>
      <link>/posts/new-perspectives-in-statistics-education/</link>
      <pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/new-perspectives-in-statistics-education/</guid>
      <description>Upcoming events: Statistical Society of Australia (SSA), Biostatistics bonanza. August 23.
Sue Finch: “Back to basics? Identifying educational needs through statistical consulting” People who come to consulting come with real need - come with an applied problem. How can we use this to inform new generation of statistical training for researchers?
Break down research cycle using PPDAC cycle used within statistical education (Wild and Pfannkuch). Process of statistical thinking when carrying out a statistical inquiry.</description>
    </item>
    
    <item>
      <title>Baranyi and da Silva (2017) The use of predictive models to optimize risk of decisions</title>
      <link>/posts/baranyi-and-da-silva-2017-the-use-of-predictive-models-to-optimize-risk-of-decisions/</link>
      <pubDate>Wed, 25 Jul 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/baranyi-and-da-silva-2017-the-use-of-predictive-models-to-optimize-risk-of-decisions/</guid>
      <description>Application domain: Microbiology decision support for predicting food borne Bacteria growth and reduce the need for microbiological testing. Approach/framework: risk assessment and decision-analytic framework.
Aims and objectives of the paper:
 The focus of this paper is not the above interpreted risk, assigned to an a-posteriori event, but the risk of an a-priory decision, that we also call choice or bet in what follows.
  In this paper we explain, backed by examples, why predictive models should be used in combination with a cost-bene fit assessment.</description>
    </item>
    
    <item>
      <title>Retreat QRP session</title>
      <link>/posts/retreat-qrp-session/</link>
      <pubDate>Fri, 20 Jul 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/retreat-qrp-session/</guid>
      <description>Summary and purpose of the workshop: We ran a workshop where we hosted small discussions attempting to propose questionable research practices that arise in ecological and conservation research using non-frequentist and/or non hypothetico-deductive inquiry.
The purpose of the workshop was two-fold:
To bring awareness to our research group of QRPs for the types of work relevant to the group, and to consider how reproducibility issues might affect us, even if reproducibility research seems irrelevant.</description>
    </item>
    
    <item>
      <title>John Blischak reproducibility and workflowr</title>
      <link>/posts/john-blischak-reproducibility-and-workflowr/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/john-blischak-reproducibility-and-workflowr/</guid>
      <description>Institutional road blocks against full reproducibility - methods sections are insufficient. But good software practice is helpful for future you, your labmates when you leave.
Lowndes et al (2017) Peng et al (2011)
Strategies for computational repro Record computing environment  sessionInfo() ## R version 3.5.0 (2018-04-23) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS Sierra 10.12.6 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_AU.</description>
    </item>
    
    <item>
      <title>Seaman &amp; Weber (2015) Undisclosed Flexibility in Computing and Reporting Structural Equation Models in Communication Science.</title>
      <link>/posts/seaman-c-s-weber-r-2015-undisclosed-flexibility-in-computing-and-reporting-structural-equation-models-in-communication-science/</link>
      <pubDate>Tue, 10 Jul 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/seaman-c-s-weber-r-2015-undisclosed-flexibility-in-computing-and-reporting-structural-equation-models-in-communication-science/</guid>
      <description>Summary This paper is a systematic review (or ‘methodological review’ in their tersm) of both QRPs and bad modelling practice in structural equation modelling within the field of communication. They don’t use the term ‘Questionable Research Practices’, however, they do explicitly look at practices falling under the QRP banner, including cherry-picking, HARKing, and researcher degrees of freedom. Importantly, this paper is really useful to me because they examine these questionable research practices in a modelling framework outside of the non-hypothetico-deductive scientific model.</description>
    </item>
    
    <item>
      <title>Schmolke et al (2010) Ecological models supporting environmental decision making: a strategy for the future</title>
      <link>/posts/schmolke-et-al-2010-ecological-models-supporting-environmental-decision-making-a-strategy-for-the-future/</link>
      <pubDate>Tue, 26 Jun 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/schmolke-et-al-2010-ecological-models-supporting-environmental-decision-making-a-strategy-for-the-future/</guid>
      <description></description>
    </item>
    
    <item>
      <title>de Vos Are Environmental Models Transparent and Reproducible?</title>
      <link>/posts/de-vos-are-environmental-models-transparent-and-reproducible/</link>
      <pubDate>Wed, 20 Jun 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/de-vos-are-environmental-models-transparent-and-reproducible/</guid>
      <description>Problem: Why is transparency and reproducibility of environmental models important? Transparency and reproducibility are quintessential for facilitating assessment of model quality and suitability by both peer-reviewers, readers, and future users:  Page 1, 2018-06-20:  Environmental models are in fact applications of shared theories on how real-world systems are functioning.
 Because “Environmental models are in fact applications of shared theories on how real-world systems are functioning”, it is essential that “the underlying scientific theories they need to be evaluated and discussed among peers.</description>
    </item>
    
    <item>
      <title>QRPs Study Planning</title>
      <link>/posts/qrps-study-planning/</link>
      <pubDate>Thu, 14 Jun 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/qrps-study-planning/</guid>
      <description>QRPs for non-hypothesis testing research in Ecology and Conservation Decision Making Problem and Background:
The reproducibility literature has focused exclusively on hypothesis-testing, whether that be Bayesian or frequentist. This also applies to initial research focusing on ecology and evolution. However, Fidler (2016) correctly identifies that in applied ecological research, particularly in conservation science, non-hypothesis testing methods, such as decision-theory, cost-effectiveness analysis, optimization and other scientific computing methods are common. These approaches come with their own set of reproducibility issues.</description>
    </item>
    
    <item>
      <title>Advisory Committee Meeting</title>
      <link>/posts/advisory-committee-meeting/</link>
      <pubDate>Mon, 04 Jun 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/advisory-committee-meeting/</guid>
      <description>Chapter 2, QRPs Scope Trying to cover the scope of the entire decision process might be too large for just one chapter. Just examining QRPs for system modelling is quite a task. PV suggested restricting the focus to decision tools and focussing on one application area, such as conservation planning / reserve design. This would also give more traction and uptake among ecologists. Conservation planning isn&amp;rsquo;t using the term &amp;lsquo;reproducibility&amp;rsquo; to describe their problems.</description>
    </item>
    
    <item>
      <title>Arguments against the existance and extent of the reproducibility crisis</title>
      <link>/posts/arguments-against-the-existance-and-extent-of-the-reproducibility-crisis/</link>
      <pubDate>Fri, 25 May 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/arguments-against-the-existance-and-extent-of-the-reproducibility-crisis/</guid>
      <description>Despite a growing body of large-scale meta-analyses across many different disciplines, debate as to whether there is a “crisis” persists. Fanelli et al. (2018) use a failed replication of a large-scale meta-analysis to argue that the “crisis” is mistaken, and should instead be re-branded as a narrative of “epochal changes and empowerment of science” (Jamieson 2018). In a ‘post-truth’ era of ‘alternative-facts’, how scientists communicate research on the robustness of science and its self-correcting mechanisms is certainly important (Sutherland and Wordley 2017).</description>
    </item>
    
    <item>
      <title>PhD Research Proposal: Reproducibility and Transparency of Decisions in Ecology and Conservation</title>
      <link>/posts/research_proposal/</link>
      <pubDate>Wed, 23 May 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/research_proposal/</guid>
      <description>Keywords:
 conservation decision-making ecology reproducibility structured decision-making  Introduction Successful biodiversity conservation and management is underpinned by effective and robust decision-making (Mukherjee et al. 2018). Decision-makers are tasked with allocating limited resources in the face of uncertainty about the effectiveness of alternative management interventions, and incomplete or inadequate scientific information. Moreover, environmental decisions often must be made in complex socio-economic and political contexts, with multiple stakeholders and multiple and/or competing objectives.</description>
    </item>
    
    <item>
      <title>proposal out-takes</title>
      <link>/posts/proposal_outtakes/</link>
      <pubDate>Tue, 22 May 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/proposal_outtakes/</guid>
      <description>Unpacking what this (“reproducibility issues”) means … what do we need to know? what is my task a. how to measure the likely reproducibility of a study b. what is the function / role of different types of replications in terms of what they tell us about the broader state of the literature (validity, generalisations) c.
how widespread the reproducibility issues identified in part I. The work from the first aim will help to inform the scoping rules and coding criteria for the systematic review.</description>
    </item>
    
    <item>
      <title>Decision Science Vocabulary</title>
      <link>/posts/decision_science_vocabulary/</link>
      <pubDate>Wed, 16 May 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/decision_science_vocabulary/</guid>
      <description>Decision Making: &amp;quot; p.56: For the purposes of this paper, we define decision-making as the process of identifying options and selecting a feasible solution, based on evidence combined with the decisionmaker’s values and experience (DeFries &amp;amp; Nagendra, 2017). – Highlighted 21 May 2018&amp;quot; (Mukherjee et al. 2018)
When is a tool a tool or a system? See heading “decision support systems” in (Dicks, Walsh, and Sutherland 2014) Dicks, L. V., Walsh, J.</description>
    </item>
    
    <item>
      <title>Fraser et al 2018 QRPs in Ecology and Evolution</title>
      <link>/posts/fraser-et-al-2018-qrps-in-ecology-and-evolution/</link>
      <pubDate>Tue, 15 May 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/fraser-et-al-2018-qrps-in-ecology-and-evolution/</guid>
      <description>Fraser, H. S., Parker, T. H., Nakagawa, S., Barnett, A., Fidler, F. (2018) Questionable Research Practices in Ecology and Evolution. doi: 10.17605/OSF.IO/AJYQG.
“Transformation process” of science communication is susceptible to confusion and corruption, has triggered both reflection and meta-research in other disciplines.
Forstmeier et al [8]:
Individual research practice is embedded in a broader culture, and promoite conditions of publication bias and type 1 errors. ‘Questionable research practices’ are fostered under conditions of publication bias, inflating false postive rates in the literature.</description>
    </item>
    
    <item>
      <title>Retreat Reproducibility Session</title>
      <link>/posts/retreat-reproducibility-session/</link>
      <pubDate>Mon, 14 May 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/retreat-reproducibility-session/</guid>
      <description>Session Planning Focus: Reproducibility in practice - QRPs.
Session aim: To help spread awareness among Qaecologists and Cebranalysts about reproducibility issues in our research practices. And then possibly provide people with the tools / solutions to overcome some of these issues.
Format: not a lecture, not an unstructured discussion.
Length 90 minutes.
Introduction: 15 minutes Introductory talk with a few slides . Led by Fiona and Hannah.
Intro by Fiona, perhaps talking about why reproducibility is important to us as ecologists, the state of reproducibility in eco/evo, an in the context of other dsciplines?</description>
    </item>
    
    <item>
      <title>Gardner et al. 2018 Decision Complacency and Conservation Planning</title>
      <link>/posts/gardner-et-al-2018-decision-complacency-and-conservation-planning/</link>
      <pubDate>Wed, 09 May 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/gardner-et-al-2018-decision-complacency-and-conservation-planning/</guid>
      <description>Gardner et al. (2018) add to knowledge-doing gap literature by defining and exemplifying what they call “Decision Complacency”
 The non-use of evidence or systematic processes to make decisions.
 Contextualising decision complacency in the knowledge-doing gap:
Researcher-practitioner divide: the case where researchers do not meet the needs of practitioners such that the information provided by conservation scientists does not allow decision-makers or practitioners to make sufficiently evidence-based decisions Evidence Complacency: Sutherland and Wordley (2017) describe a different angle of the researcher-practitioner divide where practitioners don’t use or seek available evidence, and/or don’t test the impact of their actions.</description>
    </item>
    
    <item>
      <title>Cullina et al 2018 Navigating the unfolding open data landscape in ecology and evolution</title>
      <link>/posts/cullina-et-al-2018-navigating-the-unfolding-open-data-landscape-in-ecology-and-evolution/</link>
      <pubDate>Fri, 13 Apr 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/cullina-et-al-2018-navigating-the-unfolding-open-data-landscape-in-ecology-and-evolution/</guid>
      <description>The open data movement has the capacity to provide new and powerful insights into complex systems, in ecology and evolution. However, in ecology and evolution there has not been great uptake / implementation of open data to the extent seen in other disciplines (e.g. medicine, climate sciences).
Why open data?
 identify broader eco evo processes across space, time, species reanalysing data using new statistical approaches error checking using existing data to answer new questions era of the Anthropocene: large, complicated questions with high degree of uncertainty requires combined data from multiple sources, and multidsciplinary data synthesis.</description>
    </item>
    
    <item>
      <title>Nakagawa and Parker 2015</title>
      <link>/posts/nakagawa-and-parker-2015/</link>
      <pubDate>Thu, 12 Apr 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/nakagawa-and-parker-2015/</guid>
      <description>Why do we replicate? Assess the validity of prior findings probe the generality of those findings   Levels of replication Exact (also known as “direct”): highest fidelity to the original work. But in ecology, usually can only be ‘close’ replications. Partial: there is a spectrum of partial replications, from close to limited. These have slight procedural differences. Conceptual: uses distinctly different study designs to test the same hypotheses. Quasi-replication (cross-species or system)   Assessing validity  Probing generality Conceptual replications: when results concur, we can define generality.</description>
    </item>
    
    <item>
      <title>meeting april 12 2018</title>
      <link>/posts/meeting-april-12-2018/</link>
      <pubDate>Thu, 12 Apr 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-april-12-2018/</guid>
      <description>Planning the projects and the scope of the Phd (and the format for the thesis):
 Perfectly acceptable to have disparate projects / papers comprising the thesis, and bound together with a good introduction and conclusion. Don’t have to choose between different projects.  Good to try and sit with that tension, and not having to resolve it by having a neat / tightly fitting narrative thesis.
Hannah: working on structured decision making tool with Libby.</description>
    </item>
    
    <item>
      <title>meeting</title>
      <link>/posts/meeting/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting/</guid>
      <description> Investigating appropriate systematic review methodologies Developing a framework / list of non-NHST reproducibility issues (QRP&amp;rsquo;s and other sources of bias) for decision-support tools &amp;ndash;&amp;gt; informing the coding criteria for systematic review    Fiona link.l  </description>
    </item>
    
    <item>
      <title>Fidler 2017 Metaresearch in ecology</title>
      <link>/posts/fidler-2017-metaresearch-in-ecology/</link>
      <pubDate>Wed, 21 Mar 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/fidler-2017-metaresearch-in-ecology/</guid>
      <description>Fidler, F., Chee, Y. E., Wintle, B. A., Burgman, M. A., McCarthy, M. A., Gordon, A. (2017) Metaresearch for Evaluating Reproducibility in Ecology and Evolution. BioScience doi: 10.1093/biosci/biw159.
Demonstrate that ecology and evolution as disciplines are at risk of a having low rates of reproducibility, aka a &amp;lsquo;reproducibility crisis&amp;rsquo; as others have termed it. The paper sets out to identify the different ways in which ecology is likely to have a reproducibility problem.</description>
    </item>
    
    <item>
      <title>bioinformatics workshop dockerisation</title>
      <link>/posts/bioinformatics-workshop-dockerisation/</link>
      <pubDate>Wed, 21 Mar 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/bioinformatics-workshop-dockerisation/</guid>
      <description>Slides are here: http://melbournebioinformatics.github.io/MelBioInf_docs/tutorials/docker/media/index.html#47
Docker: libraries and operating system included as well (as application). ALl dependencies distributed. AND docker containers are cross-platform. == Portable. Distributable: can store images on the docker cloud.
Docker containers can&amp;rsquo;t access host-system&amp;rsquo;s files (good for security), but limits some use-cases (especially where command line utilities used).
Docker containers are very lightweight (no overhead like what virtual machines have). Docker can share libraries&amp;hellip; so if have 3 containers running ubuntu, they all share this code, whereas VM&amp;rsquo;s have to have 3 versions, one for each instance.</description>
    </item>
    
    <item>
      <title>reproducibility for decision support tools</title>
      <link>/posts/reproducibility-for-decision-support-tools/</link>
      <pubDate>Wed, 21 Mar 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/reproducibility-for-decision-support-tools/</guid>
      <description>I&amp;rsquo;ve set aside this document for developing a parallel framework of reproducibility issues not just outside of NHST, but particular to Decision Support Tools in ecology and conservation.
WHY? Because the majority of work addressing reproducibility in and outside of ecology has focused on hypothesis testing (NHST, predominantly). And non-NHST methods are important tools in the Decision Support toolbox for conservation science and applied ecology.
From this, I hope to: a) develop the coding criteria for the systematic review b) propose some sort of gold-standard protocol for developing reproducible decision support tools</description>
    </item>
    
    <item>
      <title>meeting 15 March 2018</title>
      <link>/posts/meeting-15-march-2018/</link>
      <pubDate>Thu, 15 Mar 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-15-march-2018/</guid>
      <description>Libby, Hannah present.
Exploring systematic review methods Add my notes from CJ meeting here.
Also see: BES - will be discussed in coding club / reading club. SER (Society of ecological restoration) -&amp;gt; Australian Chapter, SERA. Other disciplines where science / evidence is used in making decision s(Ecotoxicology / Biosecurity).
Authors who have worked on systematic reviews in ecology (@TODO): - Catherine Pickering - Robin Hale - W J Sutherland</description>
    </item>
    
    <item>
      <title>reading club reproducibility</title>
      <link>/posts/reading-club-reproducibility/</link>
      <pubDate>Thu, 15 Mar 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/reading-club-reproducibility/</guid>
      <description>BES Reproducibility guidelines.
Good for YOU, and for reproducibility.
Uptake in education: Fiona new reproducibility subject at the University.
Setting up a project / programming  Archive old papers + code: local folder (Nick) RANDOM SEED&amp;hellip; forgetting to set. Compounded by long run-times and large file-sizes.  Accessibility&amp;hellip; Barriers to startign work on reproducibility, but also, what are the bare minimum standards&amp;hellip; -&amp;gt; Little changes each new time.
Statistical abstinence vs.</description>
    </item>
    
    <item>
      <title>systematic review methodologies for conservation and ecology</title>
      <link>/posts/systematic-review-methodologies-for-conservation-and-ecology/</link>
      <pubDate>Thu, 15 Mar 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/systematic-review-methodologies-for-conservation-and-ecology/</guid>
      <description>Systematic Review Methods Nakagawa and Poulin [-@Nakagawa:2012fl] recommend following the PRISMA statement, at least for meta-analyses in ecology and evolution.
PRISMA
Checklist here: http://www.prisma-statement.org/documents/PRISMA%202009%20checklist.pdf
Cochrane Review
Manual broken down into two phases of the review: 1. Developing Protocol of the review 2. Conducting Review
Writing review protocol - Formulating review questions, predefining objectives. - Medicine focused, emphasis on reporting adverse effects, on consumer needs - Choosing &amp;lsquo;outcomes&amp;rsquo;of interest (Mandatory). Assessing risk of bias of studies included in the review.</description>
    </item>
    
    <item>
      <title>French 2012 meta-analysis for expert judgment</title>
      <link>/posts/french-2012-meta-analysis-for-expert-judgment/</link>
      <pubDate>Tue, 06 Mar 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/french-2012-meta-analysis-for-expert-judgment/</guid>
      <description>French, S. (2012) Expert Judgment, Meta-analysis, and Participatory Risk Analysis. Decision Analysis. 9, 119–127.
Problem / background and paper goals Page 2 [@French:2012di] describes three types of expert elicitation problems. The third forms the focus of the paper:
 The expert problem: where the decision-maker does not have the domain knowledge and elicits judgments from a group of experts. The group decision problem: where the expert group itself is jointly responseible for the decision.</description>
    </item>
    
    <item>
      <title>meeting Fiona Hannah 1st March 2018</title>
      <link>/posts/meeting-fiona-hannah-1st-march-18/</link>
      <pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-fiona-hannah-1st-march-18/</guid>
      <description>To date:
Have been trying to determine the scope of the project. Want to look at the reproducibility of decision support tools
 what elements of existing reproducibility literature apply to this context?
 do we need a new set of criteria? Much of the repro literature especially in ecology seems to be focused on NHST, but this statistical tool is rarely used in decision science, instead it might often rely on the outputs of other studies that utilise them.</description>
    </item>
    
    <item>
      <title>Meeting Hannah</title>
      <link>/posts/meeting-hannah/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-hannah/</guid>
      <description>See Steve&amp;rsquo;s guidelines around meta-analysis from medicine. Hannah&amp;rsquo;s criteria. Conservation Biology guidelines. Guidelines / checkpoints are just around transparency. No actual checking of reproducibility.
How do decisions vs. models differ? What is particular about my problem context? values, preferences. Process vs. decision model - problem is often split into two. Decision tools as models more complex, involve not just a model of the system / domain (including decision elements), but capturing objectives, alternatives, eliciting expert judgment, involving many stakeholders.</description>
    </item>
    
    <item>
      <title>PhD Timeline and Milestones</title>
      <link>/posts/phd_timeline/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/phd_timeline/</guid>
      <description>Timeline   Milestones Milestones are documented in the RHD manual, page 4: https://app.lms.unimelb.edu.au/bbcswebdav/pid-6166800-dt-content-rid-24849943_3/orgs/COM_01654/RHD%20Handbook%20v%202017%2008%2016%20LMS%20version%202.pdf
Candidature and Confirmation: Probationary Candidate: You start your PhD as a probationary candidate and within 12 months (we recommend the ideal time of 9 to 10 months) you will go through the confirmation procedure, formalising your candidature. Purpose of Confirmation: The main purpose of the confirmation process is to determine if you have developed a detailed research plan together with your supervisor(s), to assess whether this research plan meets the requirements of the degree, and to assess if adequate progress has been made.</description>
    </item>
    
    <item>
      <title>Madin (2007) Advancing ecological research with ontologies</title>
      <link>/posts/madin-2007-advancing-ecological-research-with-ontologies/</link>
      <pubDate>Sat, 24 Feb 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/madin-2007-advancing-ecological-research-with-ontologies/</guid>
      <description>(Madin et al. 2008)
Why are ontologies relevant to ecology? Issue of effectively locating scientific data is hampered because our current approaches for describing it rely on the “ad hoc use of user-supplied keywords, and do not ensure that such terms are defined and used consistently.” The same is true when searching for relevant data, “users supply their own search terms, which are then matched against keywords assigned to datasets”. Ecology is particularly prone to this problem, and many terms often have multiple and variable meanings in different contexts.</description>
    </item>
    
    <item>
      <title>meeting</title>
      <link>/posts/meeting/</link>
      <pubDate>Thu, 22 Feb 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting/</guid>
      <description> Activities in the last week  Trying to map out the landscape of reproducibility, in particular, within ecology.  What is the magnitude of the reproducibility crisis, do people even think we have one? What&amp;rsquo;s being done? Mostly focused on efforts by individuals or research groups, as well as institutional efforts, particularly emerging in the bioinformatics discipline and focusing on computational analysis workflows and data management.
 Is there really a differnce  </description>
    </item>
    
    <item>
      <title>Hart - Towards a more reproducible ecology</title>
      <link>/posts/hart-towards-a-more-reproducible-ecology/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/hart-towards-a-more-reproducible-ecology/</guid>
      <description>Borregaard, M. K., Hart, E. M. (2018) Towards a more reproducible ecology. httpwww.ecography.orgblogtowards-more-reproducible-ecology, 1–9.
This is an editorial intro to the special edition of ecography dedicated to reproducible methods in ecology..
Page 1 Page 1, Red, Text, 2018-02-20: State of ecological research and analyses has changed.
Page 1, Red, Highlight, 2018-02-20:  A new paradigm has emerged, where individual scientists download, curate and share large amounts of data and analyse it using reproducible software packages and scripts written in languages such as R, Python and Julia.</description>
    </item>
    
    <item>
      <title>reproducibility criteria</title>
      <link>/posts/reproducibility-criteria/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/reproducibility-criteria/</guid>
      <description>I need to start thinking about how we define reproducibility for a) ecological models b) ecological models in the context of decision support.
Reviewing Fiona&amp;rsquo;s article on metaresearch on ecology would be a good place to start thinking about reproducibility in ecology.
-&amp;gt; Reproducibility in ecology&amp;hellip; why important? &amp;ldquo;the inherent complexity of the inference chain needed to advance ecology as well as the importance of ecological results to challenges important to society&amp;rdquo; https://eco.</description>
    </item>
    
    <item>
      <title>Guerrero et al 2017 Using SDM to set restoration objectives</title>
      <link>/posts/guerrero-et-al-2017-using-sdm-to-set-restoration-objectives/</link>
      <pubDate>Mon, 19 Feb 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/guerrero-et-al-2017-using-sdm-to-set-restoration-objectives/</guid>
      <description>Guerrero, A. M., Shoo, L., Iacona, G., Standish, R. J., Catterall, C. P., Rumpff, L., de Bie, K., White, Z., Matzek, V., Wilson, K. A. (2017) Using structured decision-making to set restoration objectives when multiple values and preferences exist. Restoration Ecology. 25, 858–865.
Problem: achieving restoration targets is impeded by difficulty in identifying and working towards targets, because objective setting is beset by multiple / conflicting values and preferences, and there are often time-lags in a restoration action and its desired outcome.</description>
    </item>
    
    <item>
      <title>meeting Feb 15 2018</title>
      <link>/posts/meeting-feb-15-2018/</link>
      <pubDate>Thu, 15 Feb 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-feb-15-2018/</guid>
      <description>activities -&amp;gt; working towards the research proposal -&amp;gt; also on first chapter
Reading: - trying to identify difficulties / issues in modelling applied ecological problems in general - e.g. projecting performance of conservation actions, building the evidence base in restoration ecology as new techniques emerge.
-&amp;gt; aims, trying to identify why reproducibility is important for ecological models / DSTs
defining reproducibility for ecological models (still need to justify this)</description>
    </item>
    
    <item>
      <title>McPherson et al 2018 A simulation tool to scrutinise the behaviour of functional diversity metrics</title>
      <link>/posts/mcpherson-et-al-2018-a-simulation-tool-to-scrutinise-the-behaviour-of-functional-diversity-metrics/</link>
      <pubDate>Thu, 18 Jan 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/mcpherson-et-al-2018-a-simulation-tool-to-scrutinise-the-behaviour-of-functional-diversity-metrics/</guid>
      <description>\cite{MEE3:MEE312855}
Problem
More and more indices of diversity are created with time. Accurately quantifying functional diversity is important because we want to know how biodiversity loss affects ecosystem functioning.
Functional diversity is the &amp;ldquo;values and range of functionally important traits in a community&amp;rdquo;.
The authors describe four dimensions to functional diversity:
 functional richness evenness divergence redundancy  And they each characterise how organisms interact with ecosystem functioning.
Although the choice of index should be guided by the functional diversity component of interest, there are multiple indices available for each component, and then there are synthetic indices that summarise all four components as a whole.</description>
    </item>
    
    <item>
      <title>Matzek et al (2017) Emerging approaches to successful ecologicall restoration</title>
      <link>/posts/matzek-et-al-2017-emerging-approaches-to-successful-ecologicall-restoration/</link>
      <pubDate>Thu, 21 Dec 2017 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/matzek-et-al-2017-emerging-approaches-to-successful-ecologicall-restoration/</guid>
      <description>Matzek, V., Gornish, E. S., Hulvey, K. B. (2017) Emerging approaches to successful ecological restoration: five imperatives to guide innovation (eds E. Gornish, V. Matzek, &amp;amp; K. Hulvey). Restoration Ecology. 25, S110–S113.
New techniques, approaches, and technologies are emerging and being applied in habitat restoration. This is because restoration goals are shifting towards resilience and dynamism, and because the need for efficient resource use is of increasing concern.
The paper serves as an introduction / review to the special issue of the journal.</description>
    </item>
    
    <item>
      <title>first chapter</title>
      <link>/posts/first-chapter/</link>
      <pubDate>Mon, 18 Dec 2017 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/first-chapter/</guid>
      <description>Libby has suggested an idea for the first chapter. It would be a data-based review of reproducibility issues facing decision support tools and ecological models. It would require not simply applying existing criteria for reproducibility, but would require generating criteria appropriate to DST&amp;rsquo;s and ecological models. Maybe some existing criteria apply. Maybe some don&amp;rsquo;t.
First chapter initial steps:
 identify why reproducibility is important for ecological models / decision support tools Generate a list of reproducibility criteria: - review issues facing devt of ecological models - review literature on reproducibility in ecology / conservation in general Generate a set of DST&amp;rsquo;s / models to apply the list to Figure out a way of scoring the models Apply the list and score the models  Questions:</description>
    </item>
    
    <item>
      <title>Law et al. (2017) Biol Con</title>
      <link>/posts/law-et-al-2017-biol-con/</link>
      <pubDate>Fri, 15 Dec 2017 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/law-et-al-2017-biol-con/</guid>
      <description>Law, E. A., Ferraro, P. J., Arcese, P., Bryan, B. A., Davis, K., Gordon, A., Holden, M. H., Iacona, G., Martinez, R. M., McAlpine, C. A., Rhodes, J. R., Sze, J. S., Wilson, K. A. (2017) Projecting the performance of conservation interventions. BIOC doi: 10.1016/j.biocon.2017.08.029.
Problem: Projecting the performance of conservation interventions Successful decision-making for environmental management requires reliable evidence for both the performance and efficacy of proposed conservation actions.</description>
    </item>
    
    <item>
      <title>first post</title>
      <link>/posts/first-post/</link>
      <pubDate>Wed, 13 Dec 2017 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/first-post/</guid>
      <description>Readings: Reproducibility – how to define for this context. Ecology / decision support tools.
Reproducibility of ecological models used for decision support tools.
Interested in the sorts of decisions that we make as modellers… e.g. what performance measures do we use, there are so many different ways of valuing the objectives. And depending on which measure you use, you might judge the outcomes of each of the different strategies under consideration differently….</description>
    </item>
    
    <item>
      <title>QRP and Biases Roadmap</title>
      <link>/posts/qrp_roadmap/</link>
      <pubDate>Wed, 15 Feb 2017 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/qrp_roadmap/</guid>
      <description>Goal I want to generate a “roadmap” of the sources of bias and questionable research practices (QRPs) that I think are frequently encountered when developing D in applied ecology / conservation. These biases will reduce the reproducibility of of a given decision support tool. Identifying where in the DST development process particular biases are likely to occur should serve as a launching point for proposing solutions towards minimising their occurrence and therefore increasing the reproducibility of DSTs.</description>
    </item>
    
  </channel>
</rss>