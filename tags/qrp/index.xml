<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Qrp on Elise Gould: PhD Research Notebook</title>
    <link>/tags/qrp/</link>
    <description>Recent content in Qrp on Elise Gould: PhD Research Notebook</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>elise.gould@unimelb.edu.au (Elise Gould)</managingEditor>
    <webMaster>elise.gould@unimelb.edu.au (Elise Gould)</webMaster>
    <copyright>(c) 2018 -- All rights reserved.</copyright>
    <lastBuildDate>Fri, 14 Dec 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/qrp/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Estimating background QRP rate</title>
      <link>/posts/estimating-background-qrp-rate/</link>
      <pubDate>Fri, 14 Dec 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/estimating-background-qrp-rate/</guid>
      <description>WORK IN PROGRESS – DRAFT Problem:
Have you ever done this… if so, how many times have you done this? Frequency of engagement among researchers.
This tells us a few things:
Tells us about how common these practices are. If it’s a common practice, and/or, if people are doing this repeatedly, then it’s likely that this is a more acceptabile practice (THAT person should have rated the practice as being defensible, and it’s likely that the broader sample of researchers will also think that the practice is more acceptible).</description>
    </item>
    
    <item>
      <title>Meeting December 13</title>
      <link>/posts/meeting-december-13/</link>
      <pubDate>Fri, 14 Dec 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-december-13/</guid>
      <description>Present: FF, HF, LR, EG
Recap, what we talked about 1. Scope and framing of the thesis Agreed that broad framing “reproducibility of decisions” is good to retain. Need to be be careful about explicitly framing the scope of the thesis in this framing, however.
FF reminded me of another (crucial!) point as to why biasing conditions might be unique in a decision-making context: DM under time-constraints – need to act (quickly)!</description>
    </item>
    
    <item>
      <title>pre-print Sound Inference in Compliacted Research: A Multi-Strategy Approach</title>
      <link>/posts/pre-print-sound-inference-in-compliacted-research-a-multi-strategy-approach/</link>
      <pubDate>Sun, 25 Nov 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/pre-print-sound-inference-in-compliacted-research-a-multi-strategy-approach/</guid>
      <description>Whole article: addresses the problem of people categorically dismissing pre-registration, especially in ecology.
Pre-reg can address all sorts of biases, examples of complicated research and what this might mean were good.
Conceptual Framework: Also good, liked their use of Loken and Gelman. Have been leaning towards this thinking for my own rok.
What do you think about trying this in a case study paper? A demonstration of pre-reg for ‘complicated research’ would that be a useful contribution?</description>
    </item>
    
    <item>
      <title>QRPs in non-hypothesis testing research</title>
      <link>/posts/qrps-in-non-hypothesis-testing-research/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/qrps-in-non-hypothesis-testing-research/</guid>
      <description>QRP research is NHST focussed To date, there has been limited research on QRPs and other aspects of reproducibility for non-NHST research.
Partly because: The majority of QRP research has been undertaken in Psychology, where almost all statistical testing is NHST. But this is not true for other fields eg, in applied ecology and conservation, my area of expertise, where we often use predictive modelling to systematically inform environmental decision-making. Instead, we use decision-theoretic frameworks, return-on-investment analyses, Bayesian Network models.</description>
    </item>
    
    <item>
      <title>CEBRA-workshop</title>
      <link>/posts/cebra-workshop/</link>
      <pubDate>Thu, 11 Oct 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/cebra-workshop/</guid>
      <description>Personal reflections on the CEBRA-SDM (pest-management climate modelling) workshop, emphasis on reproducibility.
Discussion with JE and JC Did I get what I need from the workshop, is it useful to me?
I’m going to assist James in collating all the butcher’s paper. From this I can attempt to generate a roadmap of the numerous subjective judgments people make during SDM. Then I will be able to map onto those decision points potential QRP analogues.</description>
    </item>
    
    <item>
      <title>Wang et al 2018 Researcher Reqeusts for Inappropriate Analysis and Reporting: A U.S. Survey of Consulting Biostatisticians</title>
      <link>/posts/wang-et-al-2018-researcher-reqeusts-for-inappropriate-analysis-and-reporting-a-u-s-survey-of-consulting-biostatisticians/</link>
      <pubDate>Wed, 10 Oct 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/wang-et-al-2018-researcher-reqeusts-for-inappropriate-analysis-and-reporting-a-u-s-survey-of-consulting-biostatisticians/</guid>
      <description>See this twitter post: https://twitter.com/EricTopol/status/1049448246894948352
The list of QRPs that were included in the survey is as follows, [Table 1][@Wang:2018ba]
 Falsify the statistical significance (such as the P value) to support a desired result Change data to achieve the desired outcome (such as the prevalence rate of cancer or another disease) Remove or alter some dta records (observations) to better support the research hypothesis Interpret the statistical findings on the basis of expectations, not the actual results Do not fully describe the treatment under study because protocol was not exactly followed Do not report the presence of key missing data that could bias the results Ignore violations of assumptions because results may change to negative Modify a measurement scale to achieve some desired results rather than adhering to the original scale as validated Report power on the basis of a post hoc calculation, but make it seem like an a priori statement Request to properly adjust for multiple testing when “a priori, originally planned secondary outcomes” are shifted to an “a posteriori primary outcome status” Conduct too many post hoc tests, but purposefully do not adjust alpha levels to make results look more impressive than they really are Remove categories of a variable to report more favourable results Do not mention interim analyses to avoid “too much testing” Report results before data have been cleaned up and validated Do not discuss the duration of follow-up because it was inconsistent Stress only the significant findings, but underreport nonsignificant ones Do not report the model statistics (including effect size in ANOVA or \(R^2\) in linear regression) because they seemed too small to indicate any meaningful changes Do not show plot because it did not show as strong as an effect as you had hoped  The table illustrates that QRPs with a lower proportion of people who thought the practice was “most severe” increase in prevalence (general trend).</description>
    </item>
    
    <item>
      <title>Thesis Bootcamp</title>
      <link>/posts/thesis-bootcamp/</link>
      <pubDate>Wed, 19 Sep 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/thesis-bootcamp/</guid>
      <description>Date of the Bootcamp: 19th - 21st October https://gradresearch.unimelb.edu.au/preparing-my-thesis/writing-the-thesis https://gradresearch.unimelb.edu.au/preparing-my-thesis/thesis-with-publication
Please provide a brief description of your research area/interests as relevant to your thesis: 
PhD Title: Transparency and Reproducibility of Decision Support Tools in Ecology and Conservation. This includes fields, such as: meta-research / meta-science, open science, conservation decision-making, structured decision making and decision theory / decision analysis, as well as ecological modelling.
Why would you like to participate in the Thesis Boot Camp?</description>
    </item>
    
    <item>
      <title>Choose your own adventure: researcher degrees of freedom and questionable research practices in ecological modelling for decision support</title>
      <link>/posts/modelling-workflows-researcher-degrees-of-freedom-and-transparency/</link>
      <pubDate>Mon, 03 Sep 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/modelling-workflows-researcher-degrees-of-freedom-and-transparency/</guid>
      <description>Abstract: Initial meta-science research in ecology and evolution suggests that the discipline is not immune to the sorts of reproducibility issues highlighted in other scientific disciplines, such as Psychology and Medicine. A recent study has revealed rates of self-reported Questionable Reserach Practices (QRPs) in ecology and evolution comprable to other disciplines. QRPs include practices such as cherry-picking, p-hacking and hypothesising after results are known (HARKing), and result in low rates of reproducibility, contributing to biased accounts of the subject domain in the body of literature.</description>
    </item>
    
    <item>
      <title>Meeting 23 August</title>
      <link>/posts/meeting-23-august/</link>
      <pubDate>Thu, 23 Aug 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-23-august/</guid>
      <description>Tasks from last week: Develop QRP list across all methods. Figure out what is general between each of the methods. Then come up with a list of QRPs specific to the method under consideration. Also think about the overarching decision / analytic process for each of the methods. Could the QRP occur at multiple points along the workflow / model building pipeline? Sampling protocol - begin writing code, journal selection. Think about elicitation measures, what they could be, and how they could be the same across each of the methods  Other things to discuss today:</description>
    </item>
    
    <item>
      <title>Bayesianism and questionable research practices</title>
      <link>/posts/bayesianism-and-questionable-research-practices/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/bayesianism-and-questionable-research-practices/</guid>
      <description>What are the different model types / applications used in ecology / conservation? what is the process for deriving, evaluating, and reporting these models? At what point in the process might QRPs arise? Can the same QRP arise at different points during the analysis?  Next actions
 read the stopping rules paper I just imported into papers add prior selection / weighting and other qaeco retreat points to the table below can we generalise overarching workflows across methods?</description>
    </item>
    
    <item>
      <title>Simonsohn (2014) </title>
      <link>/posts/simonsohn-2014/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/simonsohn-2014/</guid>
      <description>Relationship to frequentist analyses, and the potential for P-hacking Simsonohn (2014) ran two computational experiments looking at the effects of p-hacking practices on the chance of a type I error for both Bayesian confidence intervals and Bayes Factors. He compared the Bayesian methods to the frequentist methods for each.
Bayesian confidence intervals are mathematically equivalent to frequentist confidence intervals. The only real difference is that their philosophical interpretation is different (and under both inference frameworks, normality is assumed).</description>
    </item>
    
    <item>
      <title>Meeting 16 August 2018</title>
      <link>/posts/meeting-16-august-2018/</link>
      <pubDate>Sat, 18 Aug 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-16-august-2018/</guid>
      <description>Survey Sampling Design FF queried elicitation of non-experts about the prevalence of QRPs across methods they were familiar with, but hadn’t implemented themselves. Encouraged solid justification for doing this. The only reason that comes to mind for her is if increasing the sample size is the aim. But otherwise, QRP research seems to show that people are particularly forthcoming when it comes to self-reporting. So any arguments about issues around self-reporting affecting the prevalence estimates are basically moot.</description>
    </item>
    
    <item>
      <title>Morgan et al 2017 Use (and abuse) of expert elicitation in support of decision making for public policy</title>
      <link>/posts/morgan-et-al-2017-use-and-abuse-of-expert-elicitation-in-support-of-decision-making-for-public-policy/</link>
      <pubDate>Tue, 14 Aug 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/morgan-et-al-2017-use-and-abuse-of-expert-elicitation-in-support-of-decision-making-for-public-policy/</guid>
      <description>Morgan (2014) present a review of expert elicitation methods for decision support in public policy. I reviewed this paper looking for information on how to design my methods for the expert eliciation of judgments about the consequences of particular research practices on the risk of a type I error in models used in decision support in ecology and conservation.
 I draw on relevant literature and 35 y of personal experience in designing and conducting substantively detailed expert elicitations, to suggest when it does and does not make sense to perform elicitations, how they should be designed and conducted, and how I believe the results should and should not be used.</description>
    </item>
    
    <item>
      <title>2018-09-08 meeting QRP survey design</title>
      <link>/posts/meeting-qrp-survey-design/</link>
      <pubDate>Wed, 08 Aug 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/meeting-qrp-survey-design/</guid>
      <description>Themis, Ethics
 [x] Location / public / private [x] Named Researcher credentials and experience  RIOT accreditation counts for the training question. Just give one sentence spiel for the other questions. Survey Design Estimating Prevalence and Risk of QRPs \(Risk = Likelihood \times Consequence\)
Risk
% papers or researchers engaging in the practice.
If researchers:
 can compare the number of estimated vs. self-reported? Some interesting questions about whether self reporters estimate the prevalence to be greater than non-self reporters, is the self reported rate lower than the estimated rate?</description>
    </item>
    
    <item>
      <title>Dormann et al (2018) Biotic interactions in species distribution modelling\: 10 questions to guide interpretations and avoid false conclusions</title>
      <link>/posts/dormann-et-al-2018-biotic-interactions-in-species-distribution-modelling-10-questions-to-guide-interpretations-and-avoid-false-conclusions/</link>
      <pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/dormann-et-al-2018-biotic-interactions-in-species-distribution-modelling-10-questions-to-guide-interpretations-and-avoid-false-conclusions/</guid>
      <description>Problem The authors aim to address the problem of false conclusions arisng during inference of joint species distribution models – specifically, false conclusions of biotic interactions.
Approach The authors conduct a review of joint species distribution modelling to identify (from caveats and other issues ear-marked in the source papers) potential factors that confound interpretation of analyses. Next, they develop a series of questions that can be asked by the analyst and also the reviewer to guide interpretation of conclusions – are the conclusions about biotic interactions plausible?</description>
    </item>
    
    <item>
      <title>New Perspectives in Statistics Education</title>
      <link>/posts/new-perspectives-in-statistics-education/</link>
      <pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/new-perspectives-in-statistics-education/</guid>
      <description>Upcoming events: Statistical Society of Australia (SSA), Biostatistics bonanza. August 23.
Sue Finch: “Back to basics? Identifying educational needs through statistical consulting” People who come to consulting come with real need - come with an applied problem. How can we use this to inform new generation of statistical training for researchers?
Break down research cycle using PPDAC cycle used within statistical education (Wild and Pfannkuch). Process of statistical thinking when carrying out a statistical inquiry.</description>
    </item>
    
    <item>
      <title>Retreat QRP session</title>
      <link>/posts/retreat-qrp-session/</link>
      <pubDate>Fri, 20 Jul 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/retreat-qrp-session/</guid>
      <description>Summary and purpose of the workshop: We ran a workshop where we hosted small discussions attempting to propose questionable research practices that arise in ecological and conservation research using non-frequentist and/or non hypothetico-deductive inquiry.
The purpose of the workshop was two-fold:
To bring awareness to our research group of QRPs for the types of work relevant to the group, and to consider how reproducibility issues might affect us, even if reproducibility research seems irrelevant.</description>
    </item>
    
    <item>
      <title>Seaman &amp; Weber (2015) Undisclosed Flexibility in Computing and Reporting Structural Equation Models in Communication Science.</title>
      <link>/posts/seaman-c-s-weber-r-2015-undisclosed-flexibility-in-computing-and-reporting-structural-equation-models-in-communication-science/</link>
      <pubDate>Tue, 10 Jul 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/seaman-c-s-weber-r-2015-undisclosed-flexibility-in-computing-and-reporting-structural-equation-models-in-communication-science/</guid>
      <description>Summary This paper is a systematic review (or ‘methodological review’ in their tersm) of both QRPs and bad modelling practice in structural equation modelling within the field of communication. They don’t use the term ‘Questionable Research Practices’, however, they do explicitly look at practices falling under the QRP banner, including cherry-picking, HARKing, and researcher degrees of freedom. Importantly, this paper is really useful to me because they examine these questionable research practices in a modelling framework outside of the non-hypothetico-deductive scientific model.</description>
    </item>
    
    <item>
      <title>Advisory Committee Meeting</title>
      <link>/posts/advisory-committee-meeting/</link>
      <pubDate>Mon, 04 Jun 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/advisory-committee-meeting/</guid>
      <description>Chapter 2, QRPs Scope Trying to cover the scope of the entire decision process might be too large for just one chapter. Just examining QRPs for system modelling is quite a task. PV suggested restricting the focus to decision tools and focussing on one application area, such as conservation planning / reserve design. This would also give more traction and uptake among ecologists. Conservation planning isn&amp;rsquo;t using the term &amp;lsquo;reproducibility&amp;rsquo; to describe their problems.</description>
    </item>
    
    <item>
      <title>Fraser et al 2018 QRPs in Ecology and Evolution</title>
      <link>/posts/fraser-et-al-2018-qrps-in-ecology-and-evolution/</link>
      <pubDate>Tue, 15 May 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/fraser-et-al-2018-qrps-in-ecology-and-evolution/</guid>
      <description>Fraser, H. S., Parker, T. H., Nakagawa, S., Barnett, A., Fidler, F. (2018) Questionable Research Practices in Ecology and Evolution. doi: 10.17605/OSF.IO/AJYQG.
“Transformation process” of science communication is susceptible to confusion and corruption, has triggered both reflection and meta-research in other disciplines.
Forstmeier et al [8]:
Individual research practice is embedded in a broader culture, and promoite conditions of publication bias and type 1 errors. ‘Questionable research practices’ are fostered under conditions of publication bias, inflating false postive rates in the literature.</description>
    </item>
    
    <item>
      <title>Retreat Reproducibility Session</title>
      <link>/posts/retreat-reproducibility-session/</link>
      <pubDate>Mon, 14 May 2018 00:00:00 +0000</pubDate>
      <author>elise.gould@unimelb.edu.au (Elise Gould)</author>
      <guid>/posts/retreat-reproducibility-session/</guid>
      <description>Session Planning Focus: Reproducibility in practice - QRPs.
Session aim: To help spread awareness among Qaecologists and Cebranalysts about reproducibility issues in our research practices. And then possibly provide people with the tools / solutions to overcome some of these issues.
Format: not a lecture, not an unstructured discussion.
Length 90 minutes.
Introduction: 15 minutes Introductory talk with a few slides . Led by Fiona and Hannah.
Intro by Fiona, perhaps talking about why reproducibility is important to us as ecologists, the state of reproducibility in eco/evo, an in the context of other dsciplines?</description>
    </item>
    
  </channel>
</rss>